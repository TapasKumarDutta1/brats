{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brats_5e51e4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNyXR/FOjHIVUz3UZCvit2i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/brats/blob/main/brats_5e51e4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BE8ybeW8ohO",
        "outputId": "c1a8814b-b10a-4591-cdf9-da56f89ac8b0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH28Ai7h8sKd",
        "outputId": "05814a15-f4d6-44d5-d0ee-01a678f0808b"
      },
      "source": [
        "pip install medpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: medpy in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.19.5)\n",
            "Requirement already satisfied: SimpleITK>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (2.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b41zmYl81Sb"
      },
      "source": [
        "import numpy as np\n",
        "images=np.load('/content/gdrive/MyDrive/Brats2d/images.npy')\n",
        "targets=np.load('/content/gdrive/MyDrive/Brats2d/targets.npy')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUjMFxZE8zC4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images,targets, test_size=0.33, random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp7oJ7Jw8_ZO"
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self.eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "class abc(keras.layers.Layer):\n",
        "    def __init__(self,\n",
        "                 hidden_dim,\n",
        "                 **kwargs):\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.conv1=Conv1D(self.hidden_dim,1)\n",
        "        self.conv2=Conv1D(self.hidden_dim,1)\n",
        "        self.conv3=Conv1D(self.hidden_dim,1)\n",
        "        \n",
        "        self.Wq = self.Wk = self.Wv = self.Wo = None\n",
        "        self.bq = self.bk = self.bv = self.bo = None\n",
        "\n",
        "        self.intensity = self.attention = None\n",
        "        super(abc, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        \n",
        "        q, k, v = inputs\n",
        "        \n",
        "        q=self.conv1(q)\n",
        "        k=self.conv2(k)\n",
        "        v=self.conv3(v)\n",
        "        \n",
        "        \n",
        "        def scaled_dot_product_attention(inputs):\n",
        "          query, key, value = inputs\n",
        "          feature_dim = K.shape(query)[-1]\n",
        "          e = K.batch_dot(query, key, axes=2) \n",
        "          intensity = e\n",
        "          e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
        "          attention = e / K.sum(e, axis=-1, keepdims=True)\n",
        "          v = K.batch_dot(attention, value)\n",
        "          return v\n",
        "       \n",
        "       \n",
        "        y = scaled_dot_product_attention(inputs=[q,k,v])\n",
        "        \n",
        "        \n",
        "        return y\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import *\n",
        "def load_model():   \n",
        "  \n",
        "  K.clear_session() \n",
        "  mod=densenet.DenseNet121(include_top=True, weights='imagenet')\n",
        "  d = mod.get_layer('conv5_block16_concat').output\n",
        "\n",
        "  inp = mod.get_layer('conv3_block12_concat').output\n",
        "  a = Reshape((28*28,512))(inp)\n",
        "  d_a = keras.layers.UpSampling2D(interpolation='bilinear',size=(4,4))(d)\n",
        "  d_a = Reshape((28*28,1024))(d_a)\n",
        "  a = abc(hidden_dim=512)([a,d_a,a])\n",
        "  a = LayerNormalization()(a)\n",
        "  a = Reshape((28,28,512,))(a)\n",
        "  a = keras.layers.GlobalAveragePooling2D()(a)\n",
        "\n",
        "  inp = mod.get_layer('conv4_block24_concat').output\n",
        "  b = Reshape((14*14,1024))(inp)\n",
        "  d_b = keras.layers.UpSampling2D(interpolation='bilinear',size=(2,2))(d)\n",
        "  d_b = Reshape((14*14,1024))(d_b)\n",
        "  b = abc(hidden_dim=1024)([b,d_b,b])\n",
        "  b = LayerNormalization()(b)\n",
        "  b = Reshape((14,14,1024,))(b)\n",
        "  b = keras.layers.GlobalAveragePooling2D()(b)\n",
        "\n",
        "  d = keras.layers.GlobalAveragePooling2D()(d)\n",
        "  \n",
        "\n",
        "  b = Dense(3, activation=\"softmax\")(b) \n",
        "  b = Reshape((-1,3))(b) \n",
        "  a = Dense(3, activation=\"softmax\")(a) \n",
        "  a = Reshape((-1,3))(a) \n",
        "  d = Dense(3, activation=\"softmax\")(d) \n",
        "  d = Reshape((-1,3))(d) \n",
        "  \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  # mod.load_weights('../input/global-3535-fold-1-1/weights.hdf5')\n",
        "  # for layer in mod.layers:\n",
        "  #   layer.trainable=False\n",
        "  a=mod.layers[-9].output\n",
        "  b=mod.layers[-10].output\n",
        "  d=mod.layers[-11].output\n",
        "  b = Dense(1, activation=\"sigmoid\")(b) \n",
        "  b = Reshape((-1,1))(b) \n",
        "  a = Dense(1, activation=\"sigmoid\")(a) \n",
        "  a = Reshape((-1,1))(a) \n",
        "  d = Dense(1, activation=\"sigmoid\")(d) \n",
        "  d = Reshape((-1,1))(d) \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  return mod\n",
        "\n",
        "mod=load_model()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4t7V-e99Eg-"
      },
      "source": [
        "\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle))\n",
        "    return ls\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=np.repeat(labels,9)\n",
        "    del([imgV,imgR,imgH,lbl])\n",
        "    gc.collect()\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return np.asarray(images).astype('float16'), labels.astype('uint8')\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UulC6f8x9GyG",
        "outputId": "565c8bf8-59d7-4ae2-9102-9527f3912f40"
      },
      "source": [
        "import cv2\n",
        "import gc\n",
        "from tensorflow.keras.optimizers import *\n",
        "train_data = DataGenerator(X_train,y_train, batch_size=4, augment=True)\n",
        "mod.compile(optimizer=Adam(5e-5,decay=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "hist=mod.fit_generator(train_data,epochs=50)\n",
        "gc.collect()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "81/81 [==============================] - 67s 609ms/step - loss: 0.7257 - accuracy: 0.5353\n",
            "Epoch 2/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.6878 - accuracy: 0.5473\n",
            "Epoch 3/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.6785 - accuracy: 0.5737\n",
            "Epoch 4/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.6960 - accuracy: 0.5360\n",
            "Epoch 5/50\n",
            "81/81 [==============================] - 49s 597ms/step - loss: 0.6765 - accuracy: 0.5847\n",
            "Epoch 6/50\n",
            "81/81 [==============================] - 50s 609ms/step - loss: 0.6709 - accuracy: 0.5974\n",
            "Epoch 7/50\n",
            "81/81 [==============================] - 48s 591ms/step - loss: 0.6462 - accuracy: 0.6392\n",
            "Epoch 8/50\n",
            "81/81 [==============================] - 49s 600ms/step - loss: 0.6371 - accuracy: 0.6776\n",
            "Epoch 9/50\n",
            "81/81 [==============================] - 49s 597ms/step - loss: 0.5834 - accuracy: 0.7147\n",
            "Epoch 10/50\n",
            "81/81 [==============================] - 49s 597ms/step - loss: 0.5239 - accuracy: 0.7593\n",
            "Epoch 11/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.4553 - accuracy: 0.8131\n",
            "Epoch 12/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.4139 - accuracy: 0.8008\n",
            "Epoch 13/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.3431 - accuracy: 0.8443\n",
            "Epoch 14/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.2887 - accuracy: 0.8721\n",
            "Epoch 15/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.2050 - accuracy: 0.9160\n",
            "Epoch 16/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.1763 - accuracy: 0.9362\n",
            "Epoch 17/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.1286 - accuracy: 0.9564\n",
            "Epoch 18/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.1340 - accuracy: 0.9503\n",
            "Epoch 19/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.0981 - accuracy: 0.9688\n",
            "Epoch 20/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.0735 - accuracy: 0.9805\n",
            "Epoch 21/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.0626 - accuracy: 0.9815\n",
            "Epoch 22/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.0575 - accuracy: 0.9856\n",
            "Epoch 23/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.0450 - accuracy: 0.9887\n",
            "Epoch 24/50\n",
            "81/81 [==============================] - 48s 589ms/step - loss: 0.0333 - accuracy: 0.9911\n",
            "Epoch 25/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.0282 - accuracy: 0.9918\n",
            "Epoch 26/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0221 - accuracy: 0.9931\n",
            "Epoch 27/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0194 - accuracy: 0.9931\n",
            "Epoch 28/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0176 - accuracy: 0.9931\n",
            "Epoch 29/50\n",
            "81/81 [==============================] - 49s 596ms/step - loss: 0.0162 - accuracy: 0.9931\n",
            "Epoch 30/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0152 - accuracy: 0.9931\n",
            "Epoch 31/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0144 - accuracy: 0.9931\n",
            "Epoch 32/50\n",
            "81/81 [==============================] - 49s 597ms/step - loss: 0.0137 - accuracy: 0.9931\n",
            "Epoch 33/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0131 - accuracy: 0.9931\n",
            "Epoch 34/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0127 - accuracy: 0.9931\n",
            "Epoch 35/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0122 - accuracy: 0.9931\n",
            "Epoch 36/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0119 - accuracy: 0.9931\n",
            "Epoch 37/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0121 - accuracy: 0.9931\n",
            "Epoch 38/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0110 - accuracy: 0.9935\n",
            "Epoch 39/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0098 - accuracy: 0.9952\n",
            "Epoch 40/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0092 - accuracy: 0.9955\n",
            "Epoch 41/50\n",
            "81/81 [==============================] - 49s 596ms/step - loss: 0.0087 - accuracy: 0.9959\n",
            "Epoch 42/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0085 - accuracy: 0.9959\n",
            "Epoch 43/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0084 - accuracy: 0.9959\n",
            "Epoch 44/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0082 - accuracy: 0.9959\n",
            "Epoch 45/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0081 - accuracy: 0.9959\n",
            "Epoch 46/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0080 - accuracy: 0.9959\n",
            "Epoch 47/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0080 - accuracy: 0.9959\n",
            "Epoch 48/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0079 - accuracy: 0.9959\n",
            "Epoch 49/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0078 - accuracy: 0.9959\n",
            "Epoch 50/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0078 - accuracy: 0.9959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD0ya6rDBGjB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "0549b3f2-dc03-4957-c114-f00a18cb03f9"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(hist.history['loss'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f98cf0f5850>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1MYbBZvaZBI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "989b9f93-635b-40a2-ac7b-bd10b2b13c14"
      },
      "source": [
        "pre=mod.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(np.round(pre),y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6273291925465838"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6iKXL47apzO"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}