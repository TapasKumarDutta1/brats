{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brats_4e55e5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNToWSMjw2DILJQVokq1d/v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/brats/blob/main/brats_4e55e5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_HObXxmRSmq",
        "outputId": "29a3d0b3-bccd-4fc2-c4f6-ee604a2ce754"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSmd13EIRXh4",
        "outputId": "56ac7ecb-ddcb-4943-85c5-393ad76cd7ce"
      },
      "source": [
        "pip install medpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: medpy in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.19.5)\n",
            "Requirement already satisfied: SimpleITK>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdvyM_dkRYbG"
      },
      "source": [
        "import numpy as np\n",
        "images=np.load('/content/gdrive/MyDrive/Brats2d/images.npy')\n",
        "targets=np.load('/content/gdrive/MyDrive/Brats2d/targets.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEULO0HKRZWu"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images,targets, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT30jk3sRaLZ"
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self.eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "class abc(keras.layers.Layer):\n",
        "    def __init__(self,\n",
        "                 hidden_dim,\n",
        "                 **kwargs):\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.conv1=Conv1D(self.hidden_dim,1)\n",
        "        self.conv2=Conv1D(self.hidden_dim,1)\n",
        "        self.conv3=Conv1D(self.hidden_dim,1)\n",
        "        \n",
        "        self.Wq = self.Wk = self.Wv = self.Wo = None\n",
        "        self.bq = self.bk = self.bv = self.bo = None\n",
        "\n",
        "        self.intensity = self.attention = None\n",
        "        super(abc, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        \n",
        "        q, k, v = inputs\n",
        "        \n",
        "        q=self.conv1(q)\n",
        "        k=self.conv2(k)\n",
        "        v=self.conv3(v)\n",
        "        \n",
        "        \n",
        "        def scaled_dot_product_attention(inputs):\n",
        "          query, key, value = inputs\n",
        "          feature_dim = K.shape(query)[-1]\n",
        "          e = K.batch_dot(query, key, axes=2) \n",
        "          intensity = e\n",
        "          e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
        "          attention = e / K.sum(e, axis=-1, keepdims=True)\n",
        "          v = K.batch_dot(attention, value)\n",
        "          return v\n",
        "       \n",
        "       \n",
        "        y = scaled_dot_product_attention(inputs=[q,k,v])\n",
        "        \n",
        "        \n",
        "        return y\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import *\n",
        "def load_model():   \n",
        "  \n",
        "  K.clear_session() \n",
        "  mod=densenet.DenseNet121(include_top=True, weights='imagenet')\n",
        "  d = mod.get_layer('conv5_block16_concat').output\n",
        "\n",
        "  inp = mod.get_layer('conv3_block12_concat').output\n",
        "  a = Reshape((28*28,512))(inp)\n",
        "  d_a = keras.layers.UpSampling2D(interpolation='bilinear',size=(4,4))(d)\n",
        "  d_a = Reshape((28*28,1024))(d_a)\n",
        "  a = abc(hidden_dim=512)([a,d_a,a])\n",
        "  a = LayerNormalization()(a)\n",
        "  a = Reshape((28,28,512,))(a)\n",
        "  a = keras.layers.GlobalAveragePooling2D()(a)\n",
        "\n",
        "  inp = mod.get_layer('conv4_block24_concat').output\n",
        "  b = Reshape((14*14,1024))(inp)\n",
        "  d_b = keras.layers.UpSampling2D(interpolation='bilinear',size=(2,2))(d)\n",
        "  d_b = Reshape((14*14,1024))(d_b)\n",
        "  b = abc(hidden_dim=1024)([b,d_b,b])\n",
        "  b = LayerNormalization()(b)\n",
        "  b = Reshape((14,14,1024,))(b)\n",
        "  b = keras.layers.GlobalAveragePooling2D()(b)\n",
        "\n",
        "  d = keras.layers.GlobalAveragePooling2D()(d)\n",
        "  \n",
        "\n",
        "  b = Dense(3, activation=\"softmax\")(b) \n",
        "  b = Reshape((-1,3))(b) \n",
        "  a = Dense(3, activation=\"softmax\")(a) \n",
        "  a = Reshape((-1,3))(a) \n",
        "  d = Dense(3, activation=\"softmax\")(d) \n",
        "  d = Reshape((-1,3))(d) \n",
        "  \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "#   mod.load_weights('../input/global-3535-fold-1-1/weights.hdf5')\n",
        "#   for layer in mod.layers:\n",
        "#     layer.trainable=False\n",
        "  a=mod.layers[-9].output\n",
        "  b=mod.layers[-10].output\n",
        "  d=mod.layers[-11].output\n",
        "  b = Dense(1, activation=\"sigmoid\")(b) \n",
        "  b = Reshape((-1,1))(b) \n",
        "  a = Dense(1, activation=\"sigmoid\")(a) \n",
        "  a = Reshape((-1,1))(a) \n",
        "  d = Dense(1, activation=\"sigmoid\")(d) \n",
        "  d = Reshape((-1,1))(d) \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  return mod\n",
        "\n",
        "mod=load_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHEaa5oJRgFm"
      },
      "source": [
        "\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle))\n",
        "    return ls\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=np.repeat(labels,9)\n",
        "    del([imgV,imgR,imgH,lbl])\n",
        "    gc.collect()\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return np.asarray(images).astype('float16'), labels.astype('uint8')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIekIxDcRhC5",
        "outputId": "063bd482-2ab6-4532-8772-8075decf4d55"
      },
      "source": [
        "import cv2\n",
        "import gc\n",
        "from tensorflow.keras.optimizers import *\n",
        "train_data = DataGenerator(X_train,y_train, batch_size=4, augment=True)\n",
        "mod.compile(optimizer=Adam(4e-5,decay=5e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "hist=mod.fit_generator(train_data,epochs=50)\n",
        "gc.collect()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "81/81 [==============================] - 62s 558ms/step - loss: 0.7013 - accuracy: 0.5490\n",
            "Epoch 2/50\n",
            "81/81 [==============================] - 46s 566ms/step - loss: 0.6858 - accuracy: 0.5538\n",
            "Epoch 3/50\n",
            "81/81 [==============================] - 47s 578ms/step - loss: 0.6877 - accuracy: 0.5538\n",
            "Epoch 4/50\n",
            "81/81 [==============================] - 47s 578ms/step - loss: 0.6737 - accuracy: 0.6001\n",
            "Epoch 5/50\n",
            "81/81 [==============================] - 47s 582ms/step - loss: 0.6582 - accuracy: 0.6204\n",
            "Epoch 6/50\n",
            "81/81 [==============================] - 48s 587ms/step - loss: 0.6221 - accuracy: 0.6951\n",
            "Epoch 7/50\n",
            "81/81 [==============================] - 48s 590ms/step - loss: 0.6117 - accuracy: 0.6920\n",
            "Epoch 8/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.5515 - accuracy: 0.7449\n",
            "Epoch 9/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.5122 - accuracy: 0.7809\n",
            "Epoch 10/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.4227 - accuracy: 0.8495\n",
            "Epoch 11/50\n",
            "81/81 [==============================] - 49s 597ms/step - loss: 0.3616 - accuracy: 0.8961\n",
            "Epoch 12/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.3235 - accuracy: 0.9228\n",
            "Epoch 13/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2925 - accuracy: 0.9410\n",
            "Epoch 14/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.2762 - accuracy: 0.9420\n",
            "Epoch 15/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.2673 - accuracy: 0.9496\n",
            "Epoch 16/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.2633 - accuracy: 0.9486\n",
            "Epoch 17/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.2419 - accuracy: 0.9623\n",
            "Epoch 18/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.2526 - accuracy: 0.9527\n",
            "Epoch 19/50\n",
            "81/81 [==============================] - 49s 597ms/step - loss: 0.2513 - accuracy: 0.9578\n",
            "Epoch 20/50\n",
            "81/81 [==============================] - 49s 596ms/step - loss: 0.2438 - accuracy: 0.9582\n",
            "Epoch 21/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.2428 - accuracy: 0.9568\n",
            "Epoch 22/50\n",
            "81/81 [==============================] - 48s 587ms/step - loss: 0.2444 - accuracy: 0.9612\n",
            "Epoch 23/50\n",
            "81/81 [==============================] - 48s 591ms/step - loss: 0.2290 - accuracy: 0.9684\n",
            "Epoch 24/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.2234 - accuracy: 0.9743\n",
            "Epoch 25/50\n",
            "81/81 [==============================] - 48s 594ms/step - loss: 0.2146 - accuracy: 0.9757\n",
            "Epoch 26/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.2089 - accuracy: 0.9787\n",
            "Epoch 27/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.2074 - accuracy: 0.9784\n",
            "Epoch 28/50\n",
            "81/81 [==============================] - 49s 596ms/step - loss: 0.2110 - accuracy: 0.9767\n",
            "Epoch 29/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.2203 - accuracy: 0.9719\n",
            "Epoch 30/50\n",
            "81/81 [==============================] - 49s 596ms/step - loss: 0.2148 - accuracy: 0.9739\n",
            "Epoch 31/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.2276 - accuracy: 0.9650\n",
            "Epoch 32/50\n",
            "81/81 [==============================] - 49s 597ms/step - loss: 0.3139 - accuracy: 0.9228\n",
            "Epoch 33/50\n",
            "81/81 [==============================] - 49s 596ms/step - loss: 0.2879 - accuracy: 0.9294\n",
            "Epoch 34/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.2500 - accuracy: 0.9513\n",
            "Epoch 35/50\n",
            "81/81 [==============================] - 48s 587ms/step - loss: 0.2257 - accuracy: 0.9671\n",
            "Epoch 36/50\n",
            "81/81 [==============================] - 48s 590ms/step - loss: 0.2157 - accuracy: 0.9733\n",
            "Epoch 37/50\n",
            "81/81 [==============================] - 48s 593ms/step - loss: 0.2093 - accuracy: 0.9770\n",
            "Epoch 38/50\n",
            "81/81 [==============================] - 48s 594ms/step - loss: 0.2077 - accuracy: 0.9774\n",
            "Epoch 39/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.2069 - accuracy: 0.9781\n",
            "Epoch 40/50\n",
            "81/81 [==============================] - 49s 597ms/step - loss: 0.2152 - accuracy: 0.9722\n",
            "Epoch 41/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.2123 - accuracy: 0.9750\n",
            "Epoch 42/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.2109 - accuracy: 0.9777\n",
            "Epoch 43/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2084 - accuracy: 0.9781\n",
            "Epoch 44/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.2066 - accuracy: 0.9794\n",
            "Epoch 45/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2023 - accuracy: 0.9825\n",
            "Epoch 46/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2031 - accuracy: 0.9818\n",
            "Epoch 47/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2076 - accuracy: 0.9791\n",
            "Epoch 48/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2111 - accuracy: 0.9798\n",
            "Epoch 49/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.2162 - accuracy: 0.9705\n",
            "Epoch 50/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2128 - accuracy: 0.9757\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc6Eq8C0Ri9m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "e39195c6-9525-4f57-f614-f50874f8ac1c"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(hist.history['loss'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f875e1303d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx5urG9Zak78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186678df-0bbf-4571-fbe7-34442b129698"
      },
      "source": [
        "pre=mod.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(np.round(pre),y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5341614906832298"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H5XY-IcasPP"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}