{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brats_2e5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMVJjaAb1VTma3jBylO5mc9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/brats/blob/main/brats_2e5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlYd0EBjRuII",
        "outputId": "6425b760-86a5-41cf-e7f5-760d6c2e4522"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHtASkYyRyuZ",
        "outputId": "49fb686d-5423-4fac-c973-ae40b4423cc5"
      },
      "source": [
        "pip install medpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting medpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/70/c1fd5dd60242eee81774696ea7ba4caafac2bad8f028bba94b1af83777d7/MedPy-0.4.0.tar.gz (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 29.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.19.5)\n",
            "Collecting SimpleITK>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/6b/85df5eb3a8059b23a53a9f224476e75473f9bcc0a8583ed1a9c34619f372/SimpleITK-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (47.4MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4MB 61kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: medpy\n",
            "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for medpy: filename=MedPy-0.4.0-cp37-cp37m-linux_x86_64.whl size=754474 sha256=399e250a74326e7cfd0c46117814da072ce9895a8c2e30413205dd770170251f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/c9/9c/2c6281c7a72b9fb1570862a4f028af7ce38405008354fbf870\n",
            "Successfully built medpy\n",
            "Installing collected packages: SimpleITK, medpy\n",
            "Successfully installed SimpleITK-2.0.2 medpy-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REYHWqKTR0J_"
      },
      "source": [
        "import numpy as np\n",
        "images=np.load('/content/gdrive/MyDrive/Brats2d/images.npy')\n",
        "targets=np.load('/content/gdrive/MyDrive/Brats2d/targets.npy')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOT0lvrWR7_H"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images,targets, test_size=0.33, random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcfIZWIvR9Ye",
        "outputId": "d53cd6eb-0bc1-48cd-c8cc-8ff2cf537460"
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self.eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "class abc(keras.layers.Layer):\n",
        "    def __init__(self,\n",
        "                 hidden_dim,\n",
        "                 **kwargs):\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.conv1=Conv1D(self.hidden_dim,1)\n",
        "        self.conv2=Conv1D(self.hidden_dim,1)\n",
        "        self.conv3=Conv1D(self.hidden_dim,1)\n",
        "        \n",
        "        self.Wq = self.Wk = self.Wv = self.Wo = None\n",
        "        self.bq = self.bk = self.bv = self.bo = None\n",
        "\n",
        "        self.intensity = self.attention = None\n",
        "        super(abc, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        \n",
        "        q, k, v = inputs\n",
        "        \n",
        "        q=self.conv1(q)\n",
        "        k=self.conv2(k)\n",
        "        v=self.conv3(v)\n",
        "        \n",
        "        \n",
        "        def scaled_dot_product_attention(inputs):\n",
        "          query, key, value = inputs\n",
        "          feature_dim = K.shape(query)[-1]\n",
        "          e = K.batch_dot(query, key, axes=2) \n",
        "          intensity = e\n",
        "          e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
        "          attention = e / K.sum(e, axis=-1, keepdims=True)\n",
        "          v = K.batch_dot(attention, value)\n",
        "          return v\n",
        "       \n",
        "       \n",
        "        y = scaled_dot_product_attention(inputs=[q,k,v])\n",
        "        \n",
        "        \n",
        "        return y\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import *\n",
        "def load_model():   \n",
        "  \n",
        "  K.clear_session() \n",
        "  mod=densenet.DenseNet121(include_top=True, weights='imagenet')\n",
        "  d = mod.get_layer('conv5_block16_concat').output\n",
        "\n",
        "  inp = mod.get_layer('conv3_block12_concat').output\n",
        "  a = Reshape((28*28,512))(inp)\n",
        "  d_a = keras.layers.UpSampling2D(interpolation='bilinear',size=(4,4))(d)\n",
        "  d_a = Reshape((28*28,1024))(d_a)\n",
        "  a = abc(hidden_dim=512)([a,d_a,a])\n",
        "  a = LayerNormalization()(a)\n",
        "  a = Reshape((28,28,512,))(a)\n",
        "  a = keras.layers.GlobalAveragePooling2D()(a)\n",
        "\n",
        "  inp = mod.get_layer('conv4_block24_concat').output\n",
        "  b = Reshape((14*14,1024))(inp)\n",
        "  d_b = keras.layers.UpSampling2D(interpolation='bilinear',size=(2,2))(d)\n",
        "  d_b = Reshape((14*14,1024))(d_b)\n",
        "  b = abc(hidden_dim=1024)([b,d_b,b])\n",
        "  b = LayerNormalization()(b)\n",
        "  b = Reshape((14,14,1024,))(b)\n",
        "  b = keras.layers.GlobalAveragePooling2D()(b)\n",
        "\n",
        "  d = keras.layers.GlobalAveragePooling2D()(d)\n",
        "  \n",
        "\n",
        "  b = Dense(3, activation=\"softmax\")(b) \n",
        "  b = Reshape((-1,3))(b) \n",
        "  a = Dense(3, activation=\"softmax\")(a) \n",
        "  a = Reshape((-1,3))(a) \n",
        "  d = Dense(3, activation=\"softmax\")(d) \n",
        "  d = Reshape((-1,3))(d) \n",
        "  \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "#   mod.load_weights('../input/global-3535-fold-1-1/weights.hdf5')\n",
        "#   for layer in mod.layers:\n",
        "#     layer.trainable=False\n",
        "  a=mod.layers[-9].output\n",
        "  b=mod.layers[-10].output\n",
        "  d=mod.layers[-11].output\n",
        "  b = Dense(1, activation=\"sigmoid\")(b) \n",
        "  b = Reshape((-1,1))(b) \n",
        "  a = Dense(1, activation=\"sigmoid\")(a) \n",
        "  a = Reshape((-1,1))(a) \n",
        "  d = Dense(1, activation=\"sigmoid\")(d) \n",
        "  d = Reshape((-1,1))(d) \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  return mod\n",
        "\n",
        "mod=load_model()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels.h5\n",
            "33193984/33188688 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFOM3uzSR-0W"
      },
      "source": [
        "\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle))\n",
        "    return ls\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=np.repeat(labels,9)\n",
        "    del([imgV,imgR,imgH,lbl])\n",
        "    gc.collect()\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return np.asarray(images).astype('float16'), labels.astype('uint8')\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSYryIU3SAHd",
        "outputId": "f6c3b80b-2fc4-4e7a-bd79-2ed6e78ec9a8"
      },
      "source": [
        "import cv2\n",
        "import gc\n",
        "from tensorflow.keras.optimizers import *\n",
        "train_data = DataGenerator(X_train,y_train, batch_size=4, augment=True)\n",
        "mod.compile(optimizer=Adam(2e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "hist=mod.fit_generator(train_data,epochs=50)\n",
        "gc.collect()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "81/81 [==============================] - 57s 583ms/step - loss: 0.6883 - accuracy: 0.5494\n",
            "Epoch 2/50\n",
            "81/81 [==============================] - 47s 578ms/step - loss: 0.6817 - accuracy: 0.5511\n",
            "Epoch 3/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.6748 - accuracy: 0.5830\n",
            "Epoch 4/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.6276 - accuracy: 0.6272\n",
            "Epoch 5/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.5681 - accuracy: 0.6842\n",
            "Epoch 6/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.5103 - accuracy: 0.7565\n",
            "Epoch 7/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.4668 - accuracy: 0.8278\n",
            "Epoch 8/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.3844 - accuracy: 0.8594\n",
            "Epoch 9/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.2965 - accuracy: 0.9098\n",
            "Epoch 10/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.2370 - accuracy: 0.9444\n",
            "Epoch 11/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.2063 - accuracy: 0.9609\n",
            "Epoch 12/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.1849 - accuracy: 0.9760\n",
            "Epoch 13/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.1777 - accuracy: 0.9777\n",
            "Epoch 14/50\n",
            "81/81 [==============================] - 47s 581ms/step - loss: 0.1637 - accuracy: 0.9825\n",
            "Epoch 15/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.1506 - accuracy: 0.9901\n",
            "Epoch 16/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.1385 - accuracy: 0.9935\n",
            "Epoch 17/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.1348 - accuracy: 0.9914\n",
            "Epoch 18/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.1213 - accuracy: 0.9962\n",
            "Epoch 19/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.1116 - accuracy: 0.9966\n",
            "Epoch 20/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.1173 - accuracy: 0.9894\n",
            "Epoch 21/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.1559 - accuracy: 0.9667\n",
            "Epoch 22/50\n",
            "81/81 [==============================] - 47s 578ms/step - loss: 0.1311 - accuracy: 0.9791\n",
            "Epoch 23/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.1263 - accuracy: 0.9787\n",
            "Epoch 24/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.1395 - accuracy: 0.9691\n",
            "Epoch 25/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.1009 - accuracy: 0.9873\n",
            "Epoch 26/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.0779 - accuracy: 0.9966\n",
            "Epoch 27/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.0669 - accuracy: 0.9986\n",
            "Epoch 28/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.0631 - accuracy: 0.9976\n",
            "Epoch 29/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.0519 - accuracy: 0.9997\n",
            "Epoch 30/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.0455 - accuracy: 0.9997\n",
            "Epoch 31/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.0401 - accuracy: 0.9997\n",
            "Epoch 32/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.0350 - accuracy: 0.9997\n",
            "Epoch 33/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.0308 - accuracy: 0.9997\n",
            "Epoch 34/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.0264 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.0230 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.0201 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.0176 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.0155 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.0119 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.0106 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.0093 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "81/81 [==============================] - 47s 573ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "81/81 [==============================] - 47s 577ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "81/81 [==============================] - 47s 580ms/step - loss: 0.0040 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "cQsjaFpnSCYF",
        "outputId": "1b953ecf-d049-4f49-9b44-5f8d8a234f50"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(hist.history['loss'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8f7007fe90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chueipcfamB1",
        "outputId": "bae7b6b0-eaba-4a2e-8017-b04e49abbc74"
      },
      "source": [
        "pre=mod.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(np.round(pre),y_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6211180124223602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmL7qZBdasw4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}