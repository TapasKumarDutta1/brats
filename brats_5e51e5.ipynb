{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "brats_5e51e5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNWAruZ9CXjDWIs/KDI0GEe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/brats/blob/main/brats_5e51e5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlYd0EBjRuII",
        "outputId": "5ba3764f-159c-4c80-92f4-f64fcd17e9ed"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHtASkYyRyuZ",
        "outputId": "d384aea7-64ee-4c4d-d13a-45365f4e3547"
      },
      "source": [
        "pip install medpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: medpy in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.19.5)\n",
            "Requirement already satisfied: SimpleITK>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (2.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REYHWqKTR0J_"
      },
      "source": [
        "import numpy as np\n",
        "images=np.load('/content/gdrive/MyDrive/Brats2d/images.npy')\n",
        "targets=np.load('/content/gdrive/MyDrive/Brats2d/targets.npy')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOT0lvrWR7_H"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images,targets, test_size=0.33, random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcfIZWIvR9Ye"
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self.eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "class abc(keras.layers.Layer):\n",
        "    def __init__(self,\n",
        "                 hidden_dim,\n",
        "                 **kwargs):\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.conv1=Conv1D(self.hidden_dim,1)\n",
        "        self.conv2=Conv1D(self.hidden_dim,1)\n",
        "        self.conv3=Conv1D(self.hidden_dim,1)\n",
        "        \n",
        "        self.Wq = self.Wk = self.Wv = self.Wo = None\n",
        "        self.bq = self.bk = self.bv = self.bo = None\n",
        "\n",
        "        self.intensity = self.attention = None\n",
        "        super(abc, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        \n",
        "        q, k, v = inputs\n",
        "        \n",
        "        q=self.conv1(q)\n",
        "        k=self.conv2(k)\n",
        "        v=self.conv3(v)\n",
        "        \n",
        "        \n",
        "        def scaled_dot_product_attention(inputs):\n",
        "          query, key, value = inputs\n",
        "          feature_dim = K.shape(query)[-1]\n",
        "          e = K.batch_dot(query, key, axes=2) \n",
        "          intensity = e\n",
        "          e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
        "          attention = e / K.sum(e, axis=-1, keepdims=True)\n",
        "          v = K.batch_dot(attention, value)\n",
        "          return v\n",
        "       \n",
        "       \n",
        "        y = scaled_dot_product_attention(inputs=[q,k,v])\n",
        "        \n",
        "        \n",
        "        return y\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import *\n",
        "def load_model():   \n",
        "  \n",
        "  K.clear_session() \n",
        "  mod=densenet.DenseNet121(include_top=True, weights='imagenet')\n",
        "  d = mod.get_layer('conv5_block16_concat').output\n",
        "\n",
        "  inp = mod.get_layer('conv3_block12_concat').output\n",
        "  a = Reshape((28*28,512))(inp)\n",
        "  d_a = keras.layers.UpSampling2D(interpolation='bilinear',size=(4,4))(d)\n",
        "  d_a = Reshape((28*28,1024))(d_a)\n",
        "  a = abc(hidden_dim=512)([a,d_a,a])\n",
        "  a = LayerNormalization()(a)\n",
        "  a = Reshape((28,28,512,))(a)\n",
        "  a = keras.layers.GlobalAveragePooling2D()(a)\n",
        "\n",
        "  inp = mod.get_layer('conv4_block24_concat').output\n",
        "  b = Reshape((14*14,1024))(inp)\n",
        "  d_b = keras.layers.UpSampling2D(interpolation='bilinear',size=(2,2))(d)\n",
        "  d_b = Reshape((14*14,1024))(d_b)\n",
        "  b = abc(hidden_dim=1024)([b,d_b,b])\n",
        "  b = LayerNormalization()(b)\n",
        "  b = Reshape((14,14,1024,))(b)\n",
        "  b = keras.layers.GlobalAveragePooling2D()(b)\n",
        "\n",
        "  d = keras.layers.GlobalAveragePooling2D()(d)\n",
        "  \n",
        "\n",
        "  b = Dense(3, activation=\"softmax\")(b) \n",
        "  b = Reshape((-1,3))(b) \n",
        "  a = Dense(3, activation=\"softmax\")(a) \n",
        "  a = Reshape((-1,3))(a) \n",
        "  d = Dense(3, activation=\"softmax\")(d) \n",
        "  d = Reshape((-1,3))(d) \n",
        "  \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "#   mod.load_weights('../input/global-3535-fold-1-1/weights.hdf5')\n",
        "#   for layer in mod.layers:\n",
        "#     layer.trainable=False\n",
        "  a=mod.layers[-9].output\n",
        "  b=mod.layers[-10].output\n",
        "  d=mod.layers[-11].output\n",
        "  b = Dense(1, activation=\"sigmoid\")(b) \n",
        "  b = Reshape((-1,1))(b) \n",
        "  a = Dense(1, activation=\"sigmoid\")(a) \n",
        "  a = Reshape((-1,1))(a) \n",
        "  d = Dense(1, activation=\"sigmoid\")(d) \n",
        "  d = Reshape((-1,1))(d) \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  return mod\n",
        "\n",
        "mod=load_model()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFOM3uzSR-0W"
      },
      "source": [
        "\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle))\n",
        "    return ls\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=np.repeat(labels,9)\n",
        "    del([imgV,imgR,imgH,lbl])\n",
        "    gc.collect()\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return np.asarray(images).astype('float16'), labels.astype('uint8')\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSYryIU3SAHd",
        "outputId": "cc98391d-b467-4644-bb3c-f550543950d4"
      },
      "source": [
        "import cv2\n",
        "import gc\n",
        "from tensorflow.keras.optimizers import *\n",
        "train_data = DataGenerator(X_train,y_train, batch_size=4, augment=True)\n",
        "mod.compile(optimizer=Adam(5e-5,decay=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "hist=mod.fit_generator(train_data,epochs=50)\n",
        "gc.collect()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "81/81 [==============================] - 44s 343ms/step - loss: 0.7055 - accuracy: 0.5254\n",
            "Epoch 2/50\n",
            "81/81 [==============================] - 28s 342ms/step - loss: 0.6868 - accuracy: 0.5494\n",
            "Epoch 3/50\n",
            "81/81 [==============================] - 28s 343ms/step - loss: 0.6824 - accuracy: 0.5497\n",
            "Epoch 4/50\n",
            "81/81 [==============================] - 28s 343ms/step - loss: 0.6765 - accuracy: 0.5772\n",
            "Epoch 5/50\n",
            "81/81 [==============================] - 28s 343ms/step - loss: 0.6710 - accuracy: 0.5957\n",
            "Epoch 6/50\n",
            "81/81 [==============================] - 28s 342ms/step - loss: 0.6469 - accuracy: 0.6406\n",
            "Epoch 7/50\n",
            "81/81 [==============================] - 28s 342ms/step - loss: 0.6386 - accuracy: 0.6787\n",
            "Epoch 8/50\n",
            "81/81 [==============================] - 28s 341ms/step - loss: 0.6105 - accuracy: 0.7164\n",
            "Epoch 9/50\n",
            "81/81 [==============================] - 28s 348ms/step - loss: 0.6009 - accuracy: 0.7071\n",
            "Epoch 10/50\n",
            "81/81 [==============================] - 28s 346ms/step - loss: 0.5842 - accuracy: 0.7401\n",
            "Epoch 11/50\n",
            "81/81 [==============================] - 28s 342ms/step - loss: 0.5390 - accuracy: 0.7905\n",
            "Epoch 12/50\n",
            "81/81 [==============================] - 28s 341ms/step - loss: 0.5093 - accuracy: 0.8032\n",
            "Epoch 13/50\n",
            "81/81 [==============================] - 28s 341ms/step - loss: 0.5071 - accuracy: 0.8028\n",
            "Epoch 14/50\n",
            "81/81 [==============================] - 28s 340ms/step - loss: 0.4435 - accuracy: 0.8556\n",
            "Epoch 15/50\n",
            "81/81 [==============================] - 28s 341ms/step - loss: 0.4043 - accuracy: 0.8930\n",
            "Epoch 16/50\n",
            "81/81 [==============================] - 28s 341ms/step - loss: 0.3736 - accuracy: 0.9095\n",
            "Epoch 17/50\n",
            "81/81 [==============================] - 28s 342ms/step - loss: 0.3557 - accuracy: 0.9194\n",
            "Epoch 18/50\n",
            "81/81 [==============================] - 28s 346ms/step - loss: 0.3593 - accuracy: 0.9194\n",
            "Epoch 19/50\n",
            "81/81 [==============================] - 29s 354ms/step - loss: 0.3144 - accuracy: 0.9465\n",
            "Epoch 20/50\n",
            "81/81 [==============================] - 29s 356ms/step - loss: 0.3053 - accuracy: 0.9544\n",
            "Epoch 21/50\n",
            "81/81 [==============================] - 29s 350ms/step - loss: 0.3111 - accuracy: 0.9448\n",
            "Epoch 22/50\n",
            "81/81 [==============================] - 29s 349ms/step - loss: 0.3085 - accuracy: 0.9465\n",
            "Epoch 23/50\n",
            "81/81 [==============================] - 29s 350ms/step - loss: 0.2947 - accuracy: 0.9554\n",
            "Epoch 24/50\n",
            "81/81 [==============================] - 29s 350ms/step - loss: 0.2852 - accuracy: 0.9616\n",
            "Epoch 25/50\n",
            "81/81 [==============================] - 28s 348ms/step - loss: 0.2626 - accuracy: 0.9753\n",
            "Epoch 26/50\n",
            "81/81 [==============================] - 29s 349ms/step - loss: 0.2605 - accuracy: 0.9777\n",
            "Epoch 27/50\n",
            "81/81 [==============================] - 28s 342ms/step - loss: 0.2621 - accuracy: 0.9746\n",
            "Epoch 28/50\n",
            "81/81 [==============================] - 28s 339ms/step - loss: 0.1420 - accuracy: 0.9753\n",
            "Epoch 29/50\n",
            "81/81 [==============================] - 28s 339ms/step - loss: 0.1773 - accuracy: 0.9417\n",
            "Epoch 30/50\n",
            "81/81 [==============================] - 28s 340ms/step - loss: 0.2122 - accuracy: 0.9283\n",
            "Epoch 31/50\n",
            "81/81 [==============================] - 28s 339ms/step - loss: 0.1907 - accuracy: 0.9396\n",
            "Epoch 32/50\n",
            "81/81 [==============================] - 28s 340ms/step - loss: 0.1102 - accuracy: 0.9664\n",
            "Epoch 33/50\n",
            "81/81 [==============================] - 28s 337ms/step - loss: 0.0617 - accuracy: 0.9808\n",
            "Epoch 34/50\n",
            "81/81 [==============================] - 28s 338ms/step - loss: 0.0236 - accuracy: 0.9894\n",
            "Epoch 35/50\n",
            "81/81 [==============================] - 28s 340ms/step - loss: 0.0167 - accuracy: 0.9921\n",
            "Epoch 36/50\n",
            "81/81 [==============================] - 28s 339ms/step - loss: 0.0138 - accuracy: 0.9925\n",
            "Epoch 37/50\n",
            "81/81 [==============================] - 28s 340ms/step - loss: 0.0102 - accuracy: 0.9966\n",
            "Epoch 38/50\n",
            "81/81 [==============================] - 27s 335ms/step - loss: 0.0079 - accuracy: 0.9990\n",
            "Epoch 39/50\n",
            "81/81 [==============================] - 27s 337ms/step - loss: 0.0071 - accuracy: 0.9997\n",
            "Epoch 40/50\n",
            "81/81 [==============================] - 28s 345ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "81/81 [==============================] - 29s 349ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "81/81 [==============================] - 29s 353ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "81/81 [==============================] - 29s 351ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "81/81 [==============================] - 29s 350ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "81/81 [==============================] - 29s 349ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "81/81 [==============================] - 28s 349ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "81/81 [==============================] - 29s 349ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "81/81 [==============================] - 29s 350ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "81/81 [==============================] - 29s 349ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "81/81 [==============================] - 28s 342ms/step - loss: 0.0047 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "cQsjaFpnSCYF",
        "outputId": "9de1d2a4-9715-4d56-ce94-685613b8a837"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(hist.history['loss'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc3ca9a61d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chueipcfamB1",
        "outputId": "d1efb50b-975c-45ae-d4cc-30f5432355a6"
      },
      "source": [
        "pre=mod.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(np.round(pre),y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6149068322981367"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmL7qZBdasw4"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}