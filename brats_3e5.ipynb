{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brats_3e5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOe1vzFwNGvVWIVij8Z7Lrw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/brats/blob/main/brats_3e5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6XmsMq2RuSb",
        "outputId": "b88b5606-7aa4-4291-e9cb-a329bb23b93b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04B7ehsPRzbR",
        "outputId": "8ea406c6-e38a-4e11-d1ea-0d9d5df19c3b"
      },
      "source": [
        "pip install medpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting medpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/70/c1fd5dd60242eee81774696ea7ba4caafac2bad8f028bba94b1af83777d7/MedPy-0.4.0.tar.gz (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.19.5)\n",
            "Collecting SimpleITK>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/6b/85df5eb3a8059b23a53a9f224476e75473f9bcc0a8583ed1a9c34619f372/SimpleITK-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (47.4MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4MB 64kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: medpy\n",
            "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for medpy: filename=MedPy-0.4.0-cp37-cp37m-linux_x86_64.whl size=754459 sha256=02f63dcea54110e2f133ee949f8ec3861af21f1ab4ab2767f20051daf40de2f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/c9/9c/2c6281c7a72b9fb1570862a4f028af7ce38405008354fbf870\n",
            "Successfully built medpy\n",
            "Installing collected packages: SimpleITK, medpy\n",
            "Successfully installed SimpleITK-2.0.2 medpy-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDCIu9l2R0iG"
      },
      "source": [
        "import numpy as np\n",
        "images=np.load('/content/gdrive/MyDrive/Brats2d/images.npy')\n",
        "targets=np.load('/content/gdrive/MyDrive/Brats2d/targets.npy')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjHEU3j_R8lm"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images,targets, test_size=0.33, random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfELm-ADR92O",
        "outputId": "1a9e74a0-6c78-4415-8421-e6c9566a02a5"
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self.eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "class abc(keras.layers.Layer):\n",
        "    def __init__(self,\n",
        "                 hidden_dim,\n",
        "                 **kwargs):\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.conv1=Conv1D(self.hidden_dim,1)\n",
        "        self.conv2=Conv1D(self.hidden_dim,1)\n",
        "        self.conv3=Conv1D(self.hidden_dim,1)\n",
        "        \n",
        "        self.Wq = self.Wk = self.Wv = self.Wo = None\n",
        "        self.bq = self.bk = self.bv = self.bo = None\n",
        "\n",
        "        self.intensity = self.attention = None\n",
        "        super(abc, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        \n",
        "        q, k, v = inputs\n",
        "        \n",
        "        q=self.conv1(q)\n",
        "        k=self.conv2(k)\n",
        "        v=self.conv3(v)\n",
        "        \n",
        "        \n",
        "        def scaled_dot_product_attention(inputs):\n",
        "          query, key, value = inputs\n",
        "          feature_dim = K.shape(query)[-1]\n",
        "          e = K.batch_dot(query, key, axes=2) \n",
        "          intensity = e\n",
        "          e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
        "          attention = e / K.sum(e, axis=-1, keepdims=True)\n",
        "          v = K.batch_dot(attention, value)\n",
        "          return v\n",
        "       \n",
        "       \n",
        "        y = scaled_dot_product_attention(inputs=[q,k,v])\n",
        "        \n",
        "        \n",
        "        return y\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import *\n",
        "def load_model():   \n",
        "  \n",
        "  K.clear_session() \n",
        "  mod=densenet.DenseNet121(include_top=True, weights='imagenet')\n",
        "  d = mod.get_layer('conv5_block16_concat').output\n",
        "\n",
        "  inp = mod.get_layer('conv3_block12_concat').output\n",
        "  a = Reshape((28*28,512))(inp)\n",
        "  d_a = keras.layers.UpSampling2D(interpolation='bilinear',size=(4,4))(d)\n",
        "  d_a = Reshape((28*28,1024))(d_a)\n",
        "  a = abc(hidden_dim=512)([a,d_a,a])\n",
        "  a = LayerNormalization()(a)\n",
        "  a = Reshape((28,28,512,))(a)\n",
        "  a = keras.layers.GlobalAveragePooling2D()(a)\n",
        "\n",
        "  inp = mod.get_layer('conv4_block24_concat').output\n",
        "  b = Reshape((14*14,1024))(inp)\n",
        "  d_b = keras.layers.UpSampling2D(interpolation='bilinear',size=(2,2))(d)\n",
        "  d_b = Reshape((14*14,1024))(d_b)\n",
        "  b = abc(hidden_dim=1024)([b,d_b,b])\n",
        "  b = LayerNormalization()(b)\n",
        "  b = Reshape((14,14,1024,))(b)\n",
        "  b = keras.layers.GlobalAveragePooling2D()(b)\n",
        "\n",
        "  d = keras.layers.GlobalAveragePooling2D()(d)\n",
        "  \n",
        "\n",
        "  b = Dense(3, activation=\"softmax\")(b) \n",
        "  b = Reshape((-1,3))(b) \n",
        "  a = Dense(3, activation=\"softmax\")(a) \n",
        "  a = Reshape((-1,3))(a) \n",
        "  d = Dense(3, activation=\"softmax\")(d) \n",
        "  d = Reshape((-1,3))(d) \n",
        "  \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "#   mod.load_weights('../input/global-3535-fold-1-1/weights.hdf5')\n",
        "#   for layer in mod.layers:\n",
        "#     layer.trainable=False\n",
        "  a=mod.layers[-9].output\n",
        "  b=mod.layers[-10].output\n",
        "  d=mod.layers[-11].output\n",
        "  b = Dense(1, activation=\"sigmoid\")(b) \n",
        "  b = Reshape((-1,1))(b) \n",
        "  a = Dense(1, activation=\"sigmoid\")(a) \n",
        "  a = Reshape((-1,1))(a) \n",
        "  d = Dense(1, activation=\"sigmoid\")(d) \n",
        "  d = Reshape((-1,1))(d) \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  return mod\n",
        "\n",
        "mod=load_model()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels.h5\n",
            "33193984/33188688 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2LI1pcWR_QG"
      },
      "source": [
        "\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle))\n",
        "    return ls\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=np.repeat(labels,9)\n",
        "    del([imgV,imgR,imgH,lbl])\n",
        "    gc.collect()\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return np.asarray(images).astype('float16'), labels.astype('uint8')\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCT6rmoxSAgl",
        "outputId": "6e583765-abdb-4bc8-b685-82f8382931b2"
      },
      "source": [
        "import cv2\n",
        "import gc\n",
        "from tensorflow.keras.optimizers import *\n",
        "train_data = DataGenerator(X_train,y_train, batch_size=4, augment=True)\n",
        "mod.compile(optimizer=Adam(3e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "hist=mod.fit_generator(train_data,epochs=50)\n",
        "gc.collect()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "81/81 [==============================] - 90s 546ms/step - loss: 0.6992 - accuracy: 0.5206\n",
            "Epoch 2/50\n",
            "81/81 [==============================] - 46s 559ms/step - loss: 0.6855 - accuracy: 0.5566\n",
            "Epoch 3/50\n",
            "81/81 [==============================] - 46s 568ms/step - loss: 0.6823 - accuracy: 0.5593\n",
            "Epoch 4/50\n",
            "81/81 [==============================] - 47s 575ms/step - loss: 0.6784 - accuracy: 0.5847\n",
            "Epoch 5/50\n",
            "81/81 [==============================] - 48s 584ms/step - loss: 0.6691 - accuracy: 0.5922\n",
            "Epoch 6/50\n",
            "81/81 [==============================] - 48s 593ms/step - loss: 0.6588 - accuracy: 0.6029\n",
            "Epoch 7/50\n",
            "81/81 [==============================] - 48s 593ms/step - loss: 0.6405 - accuracy: 0.6310\n",
            "Epoch 8/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.5663 - accuracy: 0.7325\n",
            "Epoch 9/50\n",
            "81/81 [==============================] - 48s 593ms/step - loss: 0.5367 - accuracy: 0.7740\n",
            "Epoch 10/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.5019 - accuracy: 0.8152\n",
            "Epoch 11/50\n",
            "81/81 [==============================] - 48s 593ms/step - loss: 0.4534 - accuracy: 0.8769\n",
            "Epoch 12/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.4276 - accuracy: 0.8855\n",
            "Epoch 13/50\n",
            "81/81 [==============================] - 48s 594ms/step - loss: 0.4050 - accuracy: 0.8937\n",
            "Epoch 14/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.3690 - accuracy: 0.9174\n",
            "Epoch 15/50\n",
            "81/81 [==============================] - 48s 593ms/step - loss: 0.3581 - accuracy: 0.9156\n",
            "Epoch 16/50\n",
            "81/81 [==============================] - 48s 593ms/step - loss: 0.3326 - accuracy: 0.9307\n",
            "Epoch 17/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.3147 - accuracy: 0.9352\n",
            "Epoch 18/50\n",
            "81/81 [==============================] - 48s 593ms/step - loss: 0.3121 - accuracy: 0.9376\n",
            "Epoch 19/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.2904 - accuracy: 0.9468\n",
            "Epoch 20/50\n",
            "81/81 [==============================] - 48s 590ms/step - loss: 0.2672 - accuracy: 0.9606\n",
            "Epoch 21/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.2672 - accuracy: 0.9571\n",
            "Epoch 22/50\n",
            "81/81 [==============================] - 48s 594ms/step - loss: 0.1565 - accuracy: 0.9523\n",
            "Epoch 23/50\n",
            "81/81 [==============================] - 48s 593ms/step - loss: 0.2218 - accuracy: 0.9105\n",
            "Epoch 24/50\n",
            "81/81 [==============================] - 48s 593ms/step - loss: 0.1543 - accuracy: 0.9451\n",
            "Epoch 25/50\n",
            "81/81 [==============================] - 48s 593ms/step - loss: 0.1036 - accuracy: 0.9664\n",
            "Epoch 26/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.0628 - accuracy: 0.9815\n",
            "Epoch 27/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.0400 - accuracy: 0.9914\n",
            "Epoch 28/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.0335 - accuracy: 0.9938\n",
            "Epoch 29/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.0497 - accuracy: 0.9873\n",
            "Epoch 30/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.0410 - accuracy: 0.9877\n",
            "Epoch 31/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.0483 - accuracy: 0.9866\n",
            "Epoch 32/50\n",
            "81/81 [==============================] - 48s 591ms/step - loss: 0.0326 - accuracy: 0.9911\n",
            "Epoch 33/50\n",
            "81/81 [==============================] - 48s 590ms/step - loss: 0.0354 - accuracy: 0.9880\n",
            "Epoch 34/50\n",
            "81/81 [==============================] - 48s 590ms/step - loss: 0.0263 - accuracy: 0.9942\n",
            "Epoch 35/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.0202 - accuracy: 0.9949\n",
            "Epoch 36/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.0107 - accuracy: 0.9976\n",
            "Epoch 37/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.0089 - accuracy: 0.9979\n",
            "Epoch 38/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.0078 - accuracy: 0.9983\n",
            "Epoch 39/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.0067 - accuracy: 0.9986\n",
            "Epoch 40/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.0061 - accuracy: 0.9986\n",
            "Epoch 41/50\n",
            "81/81 [==============================] - 48s 591ms/step - loss: 0.0056 - accuracy: 0.9986\n",
            "Epoch 42/50\n",
            "81/81 [==============================] - 48s 590ms/step - loss: 0.0051 - accuracy: 0.9986\n",
            "Epoch 43/50\n",
            "81/81 [==============================] - 48s 591ms/step - loss: 0.0044 - accuracy: 0.9990\n",
            "Epoch 44/50\n",
            "81/81 [==============================] - 48s 593ms/step - loss: 0.0041 - accuracy: 0.9990\n",
            "Epoch 45/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.0038 - accuracy: 0.9990\n",
            "Epoch 46/50\n",
            "81/81 [==============================] - 48s 593ms/step - loss: 0.0036 - accuracy: 0.9990\n",
            "Epoch 47/50\n",
            "81/81 [==============================] - 48s 593ms/step - loss: 0.0034 - accuracy: 0.9990\n",
            "Epoch 48/50\n",
            "81/81 [==============================] - 48s 593ms/step - loss: 0.0032 - accuracy: 0.9990\n",
            "Epoch 49/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.0030 - accuracy: 0.9990\n",
            "Epoch 50/50\n",
            "81/81 [==============================] - 48s 593ms/step - loss: 0.0029 - accuracy: 0.9990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "68xbm6wRSDru",
        "outputId": "65e9d67e-6a50-4890-a873-02325a181715"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(hist.history['loss'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f502a3501d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8ddnJhskISwJkIRgQPZF4BoQ0WrV1oJV8bYu0NpqW0vvfZS21t62tre/3nvtr3trbx+t/VmrrbZVgdqNW0Hqdat1QYKAEDYja1jDEghbksl8fn/MQCMGMkCSk5l5Px+Pecycc76Z+ZyH43sO33PO92vujoiIJL9Q0AWIiEj7UKCLiKQIBbqISIpQoIuIpAgFuohIisgI6oMLCwu9vLw8qI8XEUlKS5cu3ePuRa1tCyzQy8vLqaysDOrjRUSSkpltPtU2dbmIiKQIBbqISIpQoIuIpAgFuohIilCgi4ikiIQC3cymmtk6M6s2s7tb2f4jM1sef6w3s7r2L1VERE6nzcsWzSwM3Ae8F6gBlpjZfHdffbyNu3++RfvPABM6oFYRETmNRI7QJwHV7r7B3RuBOcD007SfCTzeHsW1pnr3IX7413Uca2ruqI8QEUlKiQR6KbC1xXJNfN07mNl5wCDg2VNsn2VmlWZWWVtbe6a1AvDMml385Nlqpv7333ipes9ZvYeISCpq75OiM4An3L3Vw2d3f8DdK9y9oqio1TtX2/Spy8/n0TsuAuDDDy7mrrnL2Xuo4awLFhFJFYkE+jagrMXygPi61sygA7tbjrtkSCFP3XkZs68Ywv+8sZ2r7n2BeZVb0exLIpLOrK0QNLMMYD1wFbEgXwJ8yN2rTmo3AngKGOQJJGtFRYW3x1gu63fV89U/rKRy834mlvfi8mFFDCrMo7ywO+V9csnNDmy4GhGRdmdmS929orVtbaadu0fMbDawCAgDv3T3KjO7B6h09/nxpjOAOYmEeXsa1i+feZ+6mLmVW/nps9X84K/r37a9b342gwpzGdYvnxHF+Yzo34Ph/fPJU9CLSIpp8wi9o7TXEfrJjjRG2LTnCBv3HGbT3sNs3BN7rN9ZT31D5ES7gb27M7I4n0uHFvGBCaU6kheRpHC6I/SUC/RTcXdq9h9l7c561u44yNqd9VRtP8CmvUfIz87gxooB3HZxOeWFuZ1Wk4jImVKgn4K7s2xrHY+8vIkn39hBJOq8e3gRt00p5/KhRYRCFmh9IiInU6AnYPfBYzy6eAuPvbaF2voGBhfm8qnLB3PDhFKyM8JBlyciAijQz0hjJMrCVTt44G8bqNp+kH49srnj0sHMvGigTqSKSOAU6GfB3XnxzT3c/8JbvPzWXnrkZHDblHJun1JOn7zsoMsTkTSlQD9Hy7fWcf/zb7Fo9U66Z4b50S3juXp0/6DLEpE0dLpA13joCRhf1pP7P3IhT3/+cob0y+dTv13K/S+8pTtTRaRLUaCfgSF985g7azLvH1vMdxau5YtPvEFDRKM+ikjXoLN8ZygnM8xPZk5gSN88/vt/32Tz3sPcf+uF6lcXkcDpCP0smBl3vmcYP5k5gTdqDnDDz15i/a76oMsSkTSnQD8H140rYe6nLuZYU5QP/OxlqncfCrokEUljCvRzNL6sJ3/41ykcaYzw5+WnGlVYRKTjKdDbQVnv7lSc15tn1uwOuhQRSWMK9HZyxYi+rN5xkJ0HjgVdioikKQV6O7lqZF8Anl2ro3QRCYYCvZ0M7ZtHac9uCnQRCYwCvZ2YGVeN7MtL1Xs41qSbjUSk8ynQ29EVI/pytKmZVzfsDboUEUlDCvR2dPHgPnTLDKvbRUQCkVCgm9lUM1tnZtVmdvcp2txsZqvNrMrMHmvfMpNDTmaYS4b04dm1uzVwl4h0ujYD3czCwH3ANGAUMNPMRp3UZijwFeASdx8N3NkBtSaFK0f0o2b/Ud7UXaMi0skSOUKfBFS7+wZ3bwTmANNPavNJ4D533w/g7mnb53DFiCJAly+KSOdLJNBLga0tlmvi61oaBgwzs5fM7FUzm9raG5nZLDOrNLPK2tras6u4iysu6Mao4h48q7tGRaSTtddJ0QxgKPBuYCbwCzPreXIjd3/A3SvcvaKoqKidPrrruXJEX5Zu2U/dkcagSxGRNJJIoG8DylosD4iva6kGmO/uTe6+EVhPLODT0pUj+9IcdV5Yn5r/ChGRrimRQF8CDDWzQWaWBcwA5p/U5k/Ejs4xs0JiXTAb2rHOpDJuQE9652bxnPrRRaQTtRno7h4BZgOLgDXAPHevMrN7zOz6eLNFwF4zWw08B3zR3dP27ppwyHj38CKeX19Lc1SXL4pI50hoCjp3XwAsOGnd11u8duCu+EOI9aP/4fVtLNuyn4ry3kGXIyJpQHeKdpB3DS0iI2Q8o24XEekkCvQOUtAtk4ryXrp8UUQ6jQK9A101oh/rdtVTs/9I0KWISBpQoHegK0bEJr14atXOgCsRkXSgQO9A5xflMmlQb3709Ho27jkcdDkikuIU6B3IzPjRLePJCIf4zOOv0xDRxBci0nEU6B2stGc3fnDTOFZtO8i3F6wNuhwRSWEK9E7w3lH9+Pglg3j45U0sqlJ/uoh0DAV6J/nytOGMLS3gi79boateRKRDKNA7SXZGmJ9+aAJRh88+voym5mjQJYlIilGgd6Lz+uTy7Q+M5fUtddz79PqgyxGRFKNA72TXjSth5qSB/L/n39LwuiLSrhToAfiP60YxvF8+X3piBQePNQVdjoikCAV6AHIyw3zvxgvYXd/ADxatC7ocEUkRCvSAjCvryW0Xl/ObVzfz+pb9QZcjIilAgR6gL1w9jH75OXz1Dyt11YuInDMFeoDyczL5r+mjWbuzngdf3Bh0OSKS5BToAXvf6P5cPaofP35mPVv26oYjETl7CvQu4L+mjyYjFOJrf15FbDY/EZEzp0DvAooLuvFvVw/jb+trmb9ie9DliEiSSijQzWyqma0zs2ozu7uV7bebWa2ZLY8/7mj/UlPbRy4uZ1xZT77xl9XUHWkMuhwRSUJtBrqZhYH7gGnAKGCmmY1qpelcdx8ffzzYznWmvHDI+PY/j2X/kSa+s1DD7IrImUvkCH0SUO3uG9y9EZgDTO/YstLTqJIefGxKOXMrt7J5r2Y4EpEzk0iglwJbWyzXxNed7INm9oaZPWFmZa29kZnNMrNKM6usrdU4Jq2ZddlgMkMhHvq7LmMUkTPTXidF/wcod/cLgKeBR1pr5O4PuHuFu1cUFRW100enlr49cpg+voTfVdaw/7D60kUkcYkE+jag5RH3gPi6E9x9r7s3xBcfBC5sn/LS0x3vGszRpmYeXbw56FJEJIkkEuhLgKFmNsjMsoAZwPyWDcysuMXi9cCa9isx/Qzvn8/lw4p45JXNmlhaRBLWZqC7ewSYDSwiFtTz3L3KzO4xs+vjzT5rZlVmtgL4LHB7RxWcLj75rsHU1jfw5+W6Ll1EEmNB3ZlYUVHhlZWVgXx2MnB3pv34RaLuLLrzMsws6JJEpAsws6XuXtHaNt0p2kWZGbMuG8z6XYc0s5GIJESB3oVde0EJ/Xpk84sXNwRdiogkAQV6F5aVEeL2KYN4qXovVdsPBF2OiHRxCvQu7kMXDSQ3K8xDGi9dRNqgQO/iCrplcvPEMuav2M6OA0eDLkdEujAFehL4+CWDiLrz8Mubgi5FRLowBXoSKOvdnWlji3ls8Rb2aTgAETkFBXqSmH3FEBoiUf7lN0t196iItEqBniRGFvfghzeN47VN+/jK71dqqjoReYeMoAuQxF03roSNew5z79PrGVSYy2euGhp0SSLShSjQk8xnrhzCxj2H+eHT6ykvzOW6cSVBlyQiXYS6XJKMmfGdD45lYnkvvvC7FSzdvD/okkSki1CgJ6HsjDA//0gFxQU5zPp1JVv3HQm6JBHpAhToSap3bhYP3TaRpuYoH394CQePNQVdkogETIGexIb0zeP+Wy9k457DfOxXSzjcEAm6JBEJkAI9yU0ZUshPZk5g+dY6PvHIEo426hp1kXSlQE8B08YWc+/N41i8cR+zflPJsSaFukg6UqCniOnjS/nuBy/gxTf38OlHX6cxEg26JBHpZAr0FHJzRRn/94YxPLN2N599fBmRZoW6SDpJKNDNbKqZrTOzajO7+zTtPmhmbmatzncnHe/Wyefxf64dxVNVO7lr3gqaoxoiQCRdtHmnqJmFgfuA9wI1wBIzm+/uq09qlw98DljcEYVK4j5x6SAaI1G++9Raigty+Mo1I4MuSUQ6QSJH6JOAanff4O6NwBxgeivtvgF8FzjWjvXJWfrXd5/PjIllPPj3jazdeTDockSkEyQS6KXA1hbLNfF1J5jZPwFl7v7k6d7IzGaZWaWZVdbWaib7jvblqSMo6JbJ1/64iqi6XkRS3jmfFDWzEHAv8IW22rr7A+5e4e4VRUVF5/rR0oZeuVncPXUElZv38/vXa4IuR0Q6WCKBvg0oa7E8IL7uuHxgDPC8mW0CJgPzdWK0a7jxwgFceF4vvr1wLXVHNNuRSCpLJNCXAEPNbJCZZQEzgPnHN7r7AXcvdPdydy8HXgWud/fKDqlYzkgoZHxj+hjqjjTy/UXrgi5HRDpQm4Hu7hFgNrAIWAPMc/cqM7vHzK7v6ALl3I0q6cHtUwbx2GtbWLG1LuhyRKSDWFBTmVVUVHhlpQ7iO0v9sSau+uEL9OuRw58+fQnhkAVdkoicBTNb6u6tdmnrTtE0kZ+TydeuHcXKbQd4bPHmoMsRkQ6gQE8j111QzCVD+vC9ReuorW8IuhwRaWcK9DRiZtwzfQzHmpq5c+4yNtQeCrokEWlHCvQ0c35RHl+/bjRLN+/nPfe+wF1zlyvYRVJEm2O5SOr5yOTzmDq6P794cQO/fmUTf1q+jRvGlzL7yiEMLsoLujwROUu6yiXN1dY3nAj2xkiUmyvK+MYNY8gM6x9vIl3R6a5y0RF6mivKz+ar14zkk+8azM+er+ZXL23CzPjWP4/BTJc2iiQTBboAsWD/j+tG0y0zzM+ef4tBhd2Zddn5QZclImdAgS5v829XD2fzviN8a8Faynp1Z9rY4qBLEpEEqaNU3iYUMn540zgmDOzJnXOXs1xDBYgkDQW6vENOZphffLSCvj2yueORJWzddyTokkQkAQp0aVVhXja/un0iDZEoH394CQePNQVdkoi0QYEupzSkbz4/v/VCNu45zKcffZ2GSHPQJYnIaSjQ5bSmDCnkWx8Yy4tv7mHmA6+yu15Txop0VQp0adPNFWXc96F/Ys2Oeqb/9CXeqNGJUpGuSIEuCXn/BcU88a8XEzLjpvtf4c/Lt7X9RyLSqRTokrDRJQXMn30J48p68rk5y/n2wjU0R4MZOkJE3kmBLmekT142v/3ERXz4ooH8/IUN3PHIEv7+5h421B7iWJNOmooESXeKyhnLygjxzX8ey8jiHvzn/CqeW1d7Yluf3CxKenajpGcON1eUcdXIfgFWKpJeEgp0M5sK/BgIAw+6+3dO2v4vwKeBZuAQMMvdV7dzrdLF3Dr5PK4e3Y8NtYfZXneU7XVH2VZ3jO11R1lZc4CnV+/iR7eMZ/r40qBLFUkLbQa6mYWB+4D3AjXAEjObf1JgP+bu98fbXw/cC0ztgHqli+mbn0Pf/Jx3rD/cEOFjDy/h83OXAyjURTpBIn3ok4Bqd9/g7o3AHGB6ywbufrDFYi6gM2VpLjc7g4c/NpFJg3rz+bnL+dMyXRUj0tESCfRSYGuL5Zr4urcxs0+b2VvA94DPtk95ksy6Z2Xwy9snctGgPtw1bzl/XFYTdEkiKa3drnJx9/vc/Xzgy8DXWmtjZrPMrNLMKmtra1trIinmeKhPHtyHu+at4A+vK9RFOkoigb4NKGuxPCC+7lTmADe0tsHdH3D3CnevKCoqSrxKSWrdssI8dNtEppzfhy/8bgW/X6pQF+kIiQT6EmComQ0ysyxgBjC/ZQMzG9pi8f3Am+1XoqSCbllhHvzoRC45v5AvPrGCJ9/YEXRJIimnzUB39wgwG1gErAHmuXuVmd0Tv6IFYLaZVZnZcuAu4LYOq1iSVresMA989EL+aWAv7py7jOfW7Q66JJGUYu7BXJBSUVHhlZWVgXy2BOvgsSY+9ItXeXPXIR75+CQmD+4TdEkiScPMlrp7RWvbdOu/dLoeOZk88rFJDOjVjTseqdTojSLtRIEugeiTl82jd0ymV24mH/3la6zbWR90SSJJT4EugelfkMOjn5hMVjjErQ8tZvPew0GXJJLU1IcugVu/q55bfv4KkWanV27WO7Z3i09aPbBP9wCqE+laTteHrtEWJXDD+uXz6B2T+dVLG4mcNL56Y3OUJ9/Ywd/erOXWPucFVKFIclCgS5cwqqQH379p3DvWuzsvVe9h1bYDAVQlklzUhy5dmpkxtrSAlQp0kTYp0KXLG11SwPpd9TRENCOSyOko0KXLG1taQFOzs37noaBLEenSFOjS5Y0p7QHAqu3qdhE5HQW6dHkDe3enR06G+tFF2qBAly7PzBhTWqArXUTaoECXpDCmtIC1O+ppao4GXYpIl6VAl6QwprSAxuYo63dpzBeRU1GgS1IYUxI7MVq17WAbLUXSlwJdkkJ5n1zysnViVOR0FOiSFEIhY3RJj4QC/XNzlvGtBWs6oSqRrkWBLkljTGkBa3YcJHKaE6O7Dh5j/ortPL54i+4slbSjQJekMba0gIZIlOraU98xunDlDtyhviHCS9V7OrE6keAp0CVpjCktAGDVaU6MPrlyB0P65pGfncHClTs7qzSRLiGhQDezqWa2zsyqzezuVrbfZWarzewNM3vGzDRwtbS7QYW5dM8Kn/IGo50HjlG5eT/XjyvhqpF9eXrNLl23LmmlzUA3szBwHzANGAXMNLNRJzVbBlS4+wXAE8D32rtQkXAbJ0YXrop1t1wztphpY4upO9LE4g37OrlKkeAkcoQ+Cah29w3u3gjMAaa3bODuz7n7kfjiq8CA9i1TJGZ0SQGrtx+kOfrOqROffGMHI/rnM6RvHpcPK6J7VpiFq3YEUKVIMBIJ9FJga4vlmvi6U/kEsLC1DWY2y8wqzayytrY28SpF4saWFnC0qZkNJ50Y3XHgKJWb93PtBcUA5GSGuWJ4XxZV7Wo1/EVSUbueFDWzW4EK4PutbXf3B9y9wt0rioqK2vOjJU2MHRA/MXrSULoL4idArxlbfGLd1DH92XOogaWb93degSIBSiTQtwFlLZYHxNe9jZm9B/h34Hp3b2if8kTebnBhLjmZIVbWvP1KlwUrdzCyuAeDi/JOrLtiRF+yMkIsWKluF0kPiQT6EmComQ0ysyxgBjC/ZQMzmwD8nFiY727/MkViMsIhRhX3eNuVLtvrjrK0RXfLcXnZGVw2tIhFVTuJqttF0kCbge7uEWA2sAhYA8xz9yozu8fMro83+z6QB/zOzJab2fxTvJ3IORtTWkDV9gMnQvr4EXjL7pbjpo3pz44Dx1hRU9epNYoEISORRu6+AFhw0rqvt3j9nnauS+SUxpQW8OtXNrNx72HOL8rjyZU7GF3Sg0GFue9o+56R/cgIGU+t2smEgb0CqFak8+hOUUk6Y0/cMXqAbXVHWbalrtWjc4CC7plMGVLIwlU7cVe3i6Q2BboknSF988jKCLFq2wEWxrtb3n+KQIdYt8uWfUdYvUNjqUtqU6BL0skMhxhZHLtj9C9v7GBMaQ/KW+luOe7qUf0IGTy1SmO7SGpToEtSGlvag2Vb6li+tY73jy05bds+edlcNKgPCxXokuIU6JKUxpTEhtKF03e3HDdtbH+qdx+ierfmJJXUpUCXpHR8KN2xpQUM7NO9zfbvG90fQEPqSkpToEtSGtYvn+KCHGZMKmu7MdCvRw4XnteLJ1fu0NUukrIU6JKUsjJCvHz3lXxo0sCE/+aGCaWs3VnP61t0k5GkJgW6JC0zw8wSbv+BCaXk52Tw8MubOq4okQAp0CVt5GZncEtFGQtX7mDngWNBlyPS7hToklZum1JOszu/fXVz0KWItDsFuqSVst7dec/Ifjz22haONTUHXY5Iu1KgS9r52JRy9h1uZP6K7UGXItKuFOiSdi4+vw/D++Xz8EubdAmjpBQFuqQdM+P2S8pZveMgr23cF3Q5Iu1GgS5p6YbxpfTsnqlLGCWlKNAlLXXLCjNj4kAWVe2kZv+RoMsRaRcKdElbH7n4PMyM3+gSRkkRCnRJW6U9u/G+0f2Y89pWjjRGgi5H5JwlFOhmNtXM1plZtZnd3cr2y8zsdTOLmNmN7V+mSMe4fcogDhxt4k/LdAmjJL82A93MwsB9wDRgFDDTzEad1GwLcDvwWHsXKNKRJpb3YlRxDx5+eaMuYZSkl8gR+iSg2t03uHsjMAeY3rKBu29y9zeAaAfUKNJhzIyPXzqI9bsOsahqV9DliJyTRAK9FNjaYrkmvu6MmdksM6s0s8ra2tqzeQuRdnfD+BIGF+Xy/UVriTTrmESSV6eeFHX3B9y9wt0rioqKOvOjRU4pIxziS+8bzlu1h/n96zVBlyNy1hIJ9G1Ay2lhBsTXiaSM943uz/iynvzo6Tc1aJckrUQCfQkw1MwGmVkWMAOY37FliXQuM+PLU0ew8+AxHtHdo5Kk2gx0d48As4FFwBpgnrtXmdk9ZnY9gJlNNLMa4Cbg52ZW1ZFFi3SEi8/vw+XDivjZ829x4GhT0OWInLGE+tDdfYG7D3P38939m/F1X3f3+fHXS9x9gLvnunsfdx/dkUWLdJQvTR3OgaNN3P/CW0GXInLGdKeoSAujSwq4YXwJv/z7Rk1TJ0lHgS5yki9cPZyoOz9+Zn3QpYicEQW6yEnKenfnwxedx7zKGt6qPRR0OSIJU6CLtGL2lUPIyQjxg0Xrgi5FJGEKdJFWFOZl88nLBrNw1U7+tl53NUtyUKCLnMIn3zWY4f3y+dRvllK5SVPVSdenQBc5hdzsDH57x0UUF+Rw+6+WsGJrXdAliZyWAl3kNIrys3n0kxfRKzeTj/7yNVZvP3hW7+PuGlJAOpwCXaQNxQXdeOyOyXTPCnPrQ4t5c1f9Gf19zf4j3Hj/K4z5j0X8y2+W8sL6WqLRU4+9vv9wI3OXbOGuuct5ft3ucy1f0ogFNah/RUWFV1ZWBvLZImdj457D3PzzVzBg3qcuprwwt82/+WvVTr74xBs0R51rLyjmr6t3se9wIwN6dWPmpIHcdOEA+vbIoe5II3+t2sVfVu7g5eo9RKJOTmaIY01Rbp9Szt3TRpCTGe74nZQuz8yWuntFq9sU6CKJe3NXPbc88Co5GSF+8qEJTCjrRShk72jXEGnm2wvW8vDLmxhbWsBPZk6gvDCXhkgzf63axeOvbeHlt/aSETJGl/SgavtBIlGnrHc3rhlbzLVjSxjaL4/vLIy9x4j++fx4xgSG988PYK+lK1Ggi7Sjqu0H+PCDi6k70kRhXjZXjijiqpH9uHRIIbnZGWzac5jZj7/Oqm0H+dglsaPr7Ix3Hl1v3HOYOUu28OqGfUwe3Jtrx5YwprQHZm//gXhu7W6++MQKDh6L8O/XjOSjF5/3jjYAkeYoZka4lR8YSR0KdJF2VnekkefW7eaZNbt5YX0t9cciZGWEuGhQb5ZtqSMcMr5/4wVcPbp/u3xebX0DX3piBc+tq+WK4UVcM7aYmv1H448j1Ow/ys6DxyjolsktE8v48EUDGdCre7t8tnQtCnSRDtTUHGXJxn08s3Y3z63bTUlBN7574wWU9uzWrp/j7vz6lc18c8EaGiNRzKB/jxwG9OrGgF7dKe3ZjfW76vnfNbG5Ua8c0ZePXFzOu4YUttotJMlJgS6SQnbXH+NIQzMlPbuRlfHOC9W21R3l8cVbmLNkC3sONVLepzszJg3kqhF9GdI3r9XuGkkeCnSRNNQQaeapVTv59SubWbp5PwDFBTlcNrSIdw0r5NIhhfTsnhVwlXKmFOgiaa5m/xFefHMPf1tfy9+r91B/LELIYHxZT2ZMHMj140t0WWSSUKCLyAmR5igraup4Yf0enlq1g/W7DtE7N4uZk8r4yORy+hfkBF2inIYCXURa5e68smEvv3ppE/+7ZhdhM6aNLeb2KeWMG1BARlg3k3c1pwv0jM4uRkS6DjNjyvmFTDm/kC17j/DrVzYxt3Ir/7NiO2ZQ0C2T3rlZ9MnNonduFr1zs+nZPZO87AzysjPIjT/HXofJy86ge3YGeVkZdM8Ok6kfhE6V0BG6mU0FfgyEgQfd/Tsnbc8Gfg1cCOwFbnH3Tad7Tx2hi3RNhxsiLFi5g637j7LvcAP7Djey91Aj+w7HHgePNdHUnNi/7LMyQnTPCpOdESI7I0xWRojsjNCJ58xwiKxw7DkzI0Rm2MgKh8gI24ltx18fX87ODLX6fuH4TVUZYSMcCpERMkLxdeEQhEOxNqEQsXVmhI63abE+ZP/4u5DR5a4KOqcjdDMLA/cB7wVqgCVmNt/dV7do9glgv7sPMbMZwHeBW869dBHpbLnZGdxUUXbaNg2RZg43NHPoWIRDDbHH4fjzkcYIhxqaOdIQ4VBjhCMNzTRGojQ2R2mIxF43RKI0NEU5FInQ1BylKeI0NcfaNEaiRKJOUyRKUzRKU7PTfJrBzDqaGfGQ50TYn3gd+sdre1ub2A+BnWL5c1cN5bpxJe1eayJdLpOAanffENs5mwNMB1oG+nTgP+OvnwB+ambmQXXQi0iHys4Ik50Rpndu51z2GI06jc1RmppjPwYnfhQizTQ0xX4ImqP+tkck6jRHozRHodn/8Toa9fiy4/HnZv/H+qg70agTdU60iTontnmLtn68DbE27k40Suw9HJx4e//HdvdYV1ZHSCTQS4GtLZZrgItO1cbdI2Z2AOgD7GnZyMxmAbMABg4ceJYli0i6CYWMnFCYnMwwGp7s1Dr1jIW7P+DuFe5eUVRU1JkfLSKS8hIJ9G1Ayw61AfF1rbYxswyggNjJURER6SSJBPoSYKiZDTKzLGAGMP+kNvOB2+KvbwSeVf+5iEjnarMPPd4nPhtYROyyxV+6e5WZ3QNUuvt84CHgN2ZWDewjFvoiItKJErqxyN0XAAtOWvf1Fq+PATe1b2kiInImdD790UsAAAOdSURBVBuXiEiKUKCLiKQIBbqISIoIbLRFM6sFNp/lnxdy0k1LaSJd9xvSd9+13+klkf0+z91bvZEnsEA/F2ZWearBaVJZuu43pO++a7/Ty7nut7pcRERShAJdRCRFJGugPxB0AQFJ1/2G9N137Xd6Oaf9Tso+dBEReadkPUIXEZGTKNBFRFJE0gW6mU01s3VmVm1mdwddT0cxs1+a2W4zW9ViXW8ze9rM3ow/9wqyxo5gZmVm9pyZrTazKjP7XHx9Su+7meWY2WtmtiK+3/8VXz/IzBbHv+9z4yOephwzC5vZMjP7S3w55ffbzDaZ2UozW25mlfF15/Q9T6pAbzG/6TRgFDDTzEYFW1WHeRiYetK6u4Fn3H0o8Ex8OdVEgC+4+yhgMvDp+H/jVN/3BuBKdx8HjAemmtlkYvPz/sjdhwD7ic3fm4o+B6xpsZwu+32Fu49vce35OX3PkyrQaTG/qbs3AsfnN0057v43YkMRtzQdeCT++hHghk4tqhO4+w53fz3+up7Y/+SlpPi+e8yh+GJm/OHAlcTm6YUU3G8AMxsAvB94ML5spMF+n8I5fc+TLdBbm9+0NKBagtDP3XfEX+8E+gVZTEczs3JgArCYNNj3eLfDcmA38DTwFlDn7pF4k1T9vv838CUgGl/uQ3rstwN/NbOl8fmW4Ry/5wmNhy5dj7u7maXsNadmlgf8HrjT3Q/GDtpiUnXf3b0ZGG9mPYE/AiMCLqnDmdm1wG53X2pm7w66nk52qbtvM7O+wNNmtrblxrP5nifbEXoi85umsl1mVgwQf94dcD0dwswyiYX5o+7+h/jqtNh3AHevA54DLgZ6xufphdT8vl8CXG9mm4h1oV4J/JjU32/cfVv8eTexH/BJnOP3PNkCPZH5TVNZy7lbbwP+HGAtHSLef/oQsMbd722xKaX33cyK4kfmmFk34L3Ezh88R2yeXkjB/Xb3r7j7AHcvJ/b/87Pu/mFSfL/NLNfM8o+/Bq4GVnGO3/Oku1PUzK4h1ud2fH7TbwZcUocws8eBdxMbTnMX8B/An4B5wEBiQw/f7O4nnzhNamZ2KfAisJJ/9Kl+lVg/esruu5ldQOwkWJjYgdY8d7/HzAYTO3LtDSwDbnX3huAq7TjxLpd/c/drU32/4/v3x/hiBvCYu3/TzPpwDt/zpAt0ERFpXbJ1uYiIyCko0EVEUoQCXUQkRSjQRURShAJdRCRFKNBFRFKEAl1EJEX8f7he8LltHyF7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Toz0vu4EanGE",
        "outputId": "369ac231-bc57-40b9-9679-8ce34ccad67a"
      },
      "source": [
        "pre=mod.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(np.round(pre),y_test)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6521739130434783"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zuv5-0tUatZJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}