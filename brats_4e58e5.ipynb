{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brats_4e58e5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMndBMnAZc4FAN/7a3aDI1G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/brats/blob/main/brats_4e58e5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_HObXxmRSmq",
        "outputId": "21b0fd8b-f0a9-439b-fe40-e9ec8bb857cb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSmd13EIRXh4",
        "outputId": "467db2e2-7fa2-4684-c5cc-6da7567c3d8c"
      },
      "source": [
        "pip install medpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: medpy in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.4.1)\n",
            "Requirement already satisfied: SimpleITK>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (2.0.2)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdvyM_dkRYbG"
      },
      "source": [
        "import numpy as np\n",
        "images=np.load('/content/gdrive/MyDrive/Brats2d/images.npy')\n",
        "targets=np.load('/content/gdrive/MyDrive/Brats2d/targets.npy')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEULO0HKRZWu"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images,targets, test_size=0.33, random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT30jk3sRaLZ"
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self.eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "class abc(keras.layers.Layer):\n",
        "    def __init__(self,\n",
        "                 hidden_dim,\n",
        "                 **kwargs):\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.conv1=Conv1D(self.hidden_dim,1)\n",
        "        self.conv2=Conv1D(self.hidden_dim,1)\n",
        "        self.conv3=Conv1D(self.hidden_dim,1)\n",
        "        \n",
        "        self.Wq = self.Wk = self.Wv = self.Wo = None\n",
        "        self.bq = self.bk = self.bv = self.bo = None\n",
        "\n",
        "        self.intensity = self.attention = None\n",
        "        super(abc, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        \n",
        "        q, k, v = inputs\n",
        "        \n",
        "        q=self.conv1(q)\n",
        "        k=self.conv2(k)\n",
        "        v=self.conv3(v)\n",
        "        \n",
        "        \n",
        "        def scaled_dot_product_attention(inputs):\n",
        "          query, key, value = inputs\n",
        "          feature_dim = K.shape(query)[-1]\n",
        "          e = K.batch_dot(query, key, axes=2) \n",
        "          intensity = e\n",
        "          e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
        "          attention = e / K.sum(e, axis=-1, keepdims=True)\n",
        "          v = K.batch_dot(attention, value)\n",
        "          return v\n",
        "       \n",
        "       \n",
        "        y = scaled_dot_product_attention(inputs=[q,k,v])\n",
        "        \n",
        "        \n",
        "        return y\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import *\n",
        "def load_model():   \n",
        "  \n",
        "  K.clear_session() \n",
        "  mod=densenet.DenseNet121(include_top=True, weights='imagenet')\n",
        "  d = mod.get_layer('conv5_block16_concat').output\n",
        "\n",
        "  inp = mod.get_layer('conv3_block12_concat').output\n",
        "  a = Reshape((28*28,512))(inp)\n",
        "  d_a = keras.layers.UpSampling2D(interpolation='bilinear',size=(4,4))(d)\n",
        "  d_a = Reshape((28*28,1024))(d_a)\n",
        "  a = abc(hidden_dim=512)([a,d_a,a])\n",
        "  a = LayerNormalization()(a)\n",
        "  a = Reshape((28,28,512,))(a)\n",
        "  a = keras.layers.GlobalAveragePooling2D()(a)\n",
        "\n",
        "  inp = mod.get_layer('conv4_block24_concat').output\n",
        "  b = Reshape((14*14,1024))(inp)\n",
        "  d_b = keras.layers.UpSampling2D(interpolation='bilinear',size=(2,2))(d)\n",
        "  d_b = Reshape((14*14,1024))(d_b)\n",
        "  b = abc(hidden_dim=1024)([b,d_b,b])\n",
        "  b = LayerNormalization()(b)\n",
        "  b = Reshape((14,14,1024,))(b)\n",
        "  b = keras.layers.GlobalAveragePooling2D()(b)\n",
        "\n",
        "  d = keras.layers.GlobalAveragePooling2D()(d)\n",
        "  \n",
        "\n",
        "  b = Dense(3, activation=\"softmax\")(b) \n",
        "  b = Reshape((-1,3))(b) \n",
        "  a = Dense(3, activation=\"softmax\")(a) \n",
        "  a = Reshape((-1,3))(a) \n",
        "  d = Dense(3, activation=\"softmax\")(d) \n",
        "  d = Reshape((-1,3))(d) \n",
        "  \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "#   mod.load_weights('../input/global-3535-fold-1-1/weights.hdf5')\n",
        "#   for layer in mod.layers:\n",
        "#     layer.trainable=False\n",
        "  a=mod.layers[-9].output\n",
        "  b=mod.layers[-10].output\n",
        "  d=mod.layers[-11].output\n",
        "  b = Dense(1, activation=\"sigmoid\")(b) \n",
        "  b = Reshape((-1,1))(b) \n",
        "  a = Dense(1, activation=\"sigmoid\")(a) \n",
        "  a = Reshape((-1,1))(a) \n",
        "  d = Dense(1, activation=\"sigmoid\")(d) \n",
        "  d = Reshape((-1,1))(d) \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  return mod\n",
        "\n",
        "mod=load_model()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHEaa5oJRgFm"
      },
      "source": [
        "\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle))\n",
        "    return ls\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=np.repeat(labels,9)\n",
        "    del([imgV,imgR,imgH,lbl])\n",
        "    gc.collect()\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return np.asarray(images).astype('float16'), labels.astype('uint8')\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIekIxDcRhC5",
        "outputId": "bc662e78-13ab-4875-be4a-0a81cb7d54a6"
      },
      "source": [
        "import cv2\n",
        "import gc\n",
        "from tensorflow.keras.optimizers import *\n",
        "train_data = DataGenerator(X_train,y_train, batch_size=4, augment=True)\n",
        "mod.compile(optimizer=Adam(5e-5,decay=8e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "hist=mod.fit_generator(train_data,epochs=50)\n",
        "gc.collect()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "81/81 [==============================] - 62s 559ms/step - loss: 0.6992 - accuracy: 0.5357\n",
            "Epoch 2/50\n",
            "81/81 [==============================] - 46s 571ms/step - loss: 0.6848 - accuracy: 0.5477\n",
            "Epoch 3/50\n",
            "81/81 [==============================] - 47s 581ms/step - loss: 0.6772 - accuracy: 0.5676\n",
            "Epoch 4/50\n",
            "81/81 [==============================] - 48s 588ms/step - loss: 0.6583 - accuracy: 0.6159\n",
            "Epoch 5/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.6312 - accuracy: 0.6766\n",
            "Epoch 6/50\n",
            "81/81 [==============================] - 49s 596ms/step - loss: 0.6061 - accuracy: 0.7287\n",
            "Epoch 7/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.5722 - accuracy: 0.7785\n",
            "Epoch 8/50\n",
            "81/81 [==============================] - 49s 600ms/step - loss: 0.5622 - accuracy: 0.7630\n",
            "Epoch 9/50\n",
            "81/81 [==============================] - 49s 600ms/step - loss: 0.5252 - accuracy: 0.7764\n",
            "Epoch 10/50\n",
            "81/81 [==============================] - 49s 600ms/step - loss: 0.5382 - accuracy: 0.7476\n",
            "Epoch 11/50\n",
            "81/81 [==============================] - 49s 600ms/step - loss: 0.4153 - accuracy: 0.8529\n",
            "Epoch 12/50\n",
            "81/81 [==============================] - 49s 601ms/step - loss: 0.3607 - accuracy: 0.8920\n",
            "Epoch 13/50\n",
            "81/81 [==============================] - 49s 601ms/step - loss: 0.3008 - accuracy: 0.9294\n",
            "Epoch 14/50\n",
            "81/81 [==============================] - 49s 602ms/step - loss: 0.2795 - accuracy: 0.9396\n",
            "Epoch 15/50\n",
            "81/81 [==============================] - 49s 601ms/step - loss: 0.2601 - accuracy: 0.9489\n",
            "Epoch 16/50\n",
            "81/81 [==============================] - 49s 601ms/step - loss: 0.2494 - accuracy: 0.9582\n",
            "Epoch 17/50\n",
            "81/81 [==============================] - 49s 600ms/step - loss: 0.2444 - accuracy: 0.9588\n",
            "Epoch 18/50\n",
            "81/81 [==============================] - 49s 602ms/step - loss: 0.2430 - accuracy: 0.9568\n",
            "Epoch 19/50\n",
            "81/81 [==============================] - 49s 600ms/step - loss: 0.2408 - accuracy: 0.9582\n",
            "Epoch 20/50\n",
            "81/81 [==============================] - 49s 600ms/step - loss: 0.2514 - accuracy: 0.9530\n",
            "Epoch 21/50\n",
            "81/81 [==============================] - 49s 600ms/step - loss: 0.2527 - accuracy: 0.9516\n",
            "Epoch 22/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2596 - accuracy: 0.9455\n",
            "Epoch 23/50\n",
            "81/81 [==============================] - 49s 600ms/step - loss: 0.2596 - accuracy: 0.9482\n",
            "Epoch 24/50\n",
            "81/81 [==============================] - 49s 600ms/step - loss: 0.2479 - accuracy: 0.9534\n",
            "Epoch 25/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2380 - accuracy: 0.9588\n",
            "Epoch 26/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2293 - accuracy: 0.9633\n",
            "Epoch 27/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2183 - accuracy: 0.9691\n",
            "Epoch 28/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2185 - accuracy: 0.9705\n",
            "Epoch 29/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2248 - accuracy: 0.9698\n",
            "Epoch 30/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2394 - accuracy: 0.9554\n",
            "Epoch 31/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2436 - accuracy: 0.9537\n",
            "Epoch 32/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.2595 - accuracy: 0.9492\n",
            "Epoch 33/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2346 - accuracy: 0.9599\n",
            "Epoch 34/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.2472 - accuracy: 0.9527\n",
            "Epoch 35/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2193 - accuracy: 0.9695\n",
            "Epoch 36/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2173 - accuracy: 0.9691\n",
            "Epoch 37/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2115 - accuracy: 0.9743\n",
            "Epoch 38/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2108 - accuracy: 0.9739\n",
            "Epoch 39/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.2154 - accuracy: 0.9736\n",
            "Epoch 40/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2119 - accuracy: 0.9750\n",
            "Epoch 41/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2090 - accuracy: 0.9767\n",
            "Epoch 42/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2118 - accuracy: 0.9760\n",
            "Epoch 43/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2049 - accuracy: 0.9794\n",
            "Epoch 44/50\n",
            "81/81 [==============================] - 47s 582ms/step - loss: 0.2019 - accuracy: 0.9811\n",
            "Epoch 45/50\n",
            "81/81 [==============================] - 48s 589ms/step - loss: 0.2015 - accuracy: 0.9811\n",
            "Epoch 46/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.2012 - accuracy: 0.9815\n",
            "Epoch 47/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.2009 - accuracy: 0.9815\n",
            "Epoch 48/50\n",
            "81/81 [==============================] - 49s 597ms/step - loss: 0.2008 - accuracy: 0.9815\n",
            "Epoch 49/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2007 - accuracy: 0.9815\n",
            "Epoch 50/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.2003 - accuracy: 0.9818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc6Eq8C0Ri9m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "49e42f3f-8ec5-4639-da26-aeae1f5ce0e0"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(hist.history['loss'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe28892b310>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx5urG9Zak78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0537fd-7fcf-46ed-9fcd-69c44bc92450"
      },
      "source": [
        "pre=mod.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(np.round(pre),y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.577639751552795"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H5XY-IcasPP"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}