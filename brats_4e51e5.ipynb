{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "brats_4e51e5.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMHDF+LtF3RFsoLMPdVHMb1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/brats/blob/main/brats_4e51e5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlYd0EBjRuII",
        "outputId": "dedcb30f-8050-4df8-88b2-54196ce564a1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHtASkYyRyuZ",
        "outputId": "701a827b-411f-4975-b3a1-4e404f1164f3"
      },
      "source": [
        "pip install medpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: medpy in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: SimpleITK>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REYHWqKTR0J_"
      },
      "source": [
        "import numpy as np\n",
        "images=np.load('/content/gdrive/MyDrive/Brats2d/images.npy')\n",
        "targets=np.load('/content/gdrive/MyDrive/Brats2d/targets.npy')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOT0lvrWR7_H"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images,targets, test_size=0.33, random_state=42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcfIZWIvR9Ye"
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self.eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "class abc(keras.layers.Layer):\n",
        "    def __init__(self,\n",
        "                 hidden_dim,\n",
        "                 **kwargs):\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.conv1=Conv1D(self.hidden_dim,1)\n",
        "        self.conv2=Conv1D(self.hidden_dim,1)\n",
        "        self.conv3=Conv1D(self.hidden_dim,1)\n",
        "        \n",
        "        self.Wq = self.Wk = self.Wv = self.Wo = None\n",
        "        self.bq = self.bk = self.bv = self.bo = None\n",
        "\n",
        "        self.intensity = self.attention = None\n",
        "        super(abc, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        \n",
        "        q, k, v = inputs\n",
        "        \n",
        "        q=self.conv1(q)\n",
        "        k=self.conv2(k)\n",
        "        v=self.conv3(v)\n",
        "        \n",
        "        \n",
        "        def scaled_dot_product_attention(inputs):\n",
        "          query, key, value = inputs\n",
        "          feature_dim = K.shape(query)[-1]\n",
        "          e = K.batch_dot(query, key, axes=2) \n",
        "          intensity = e\n",
        "          e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
        "          attention = e / K.sum(e, axis=-1, keepdims=True)\n",
        "          v = K.batch_dot(attention, value)\n",
        "          return v\n",
        "       \n",
        "       \n",
        "        y = scaled_dot_product_attention(inputs=[q,k,v])\n",
        "        \n",
        "        \n",
        "        return y\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import *\n",
        "def load_model():   \n",
        "  \n",
        "  K.clear_session() \n",
        "  mod=densenet.DenseNet121(include_top=True, weights='imagenet')\n",
        "  d = mod.get_layer('conv5_block16_concat').output\n",
        "\n",
        "  inp = mod.get_layer('conv3_block12_concat').output\n",
        "  a = Reshape((28*28,512))(inp)\n",
        "  d_a = keras.layers.UpSampling2D(interpolation='bilinear',size=(4,4))(d)\n",
        "  d_a = Reshape((28*28,1024))(d_a)\n",
        "  a = abc(hidden_dim=512)([a,d_a,a])\n",
        "  a = LayerNormalization()(a)\n",
        "  a = Reshape((28,28,512,))(a)\n",
        "  a = keras.layers.GlobalAveragePooling2D()(a)\n",
        "\n",
        "  inp = mod.get_layer('conv4_block24_concat').output\n",
        "  b = Reshape((14*14,1024))(inp)\n",
        "  d_b = keras.layers.UpSampling2D(interpolation='bilinear',size=(2,2))(d)\n",
        "  d_b = Reshape((14*14,1024))(d_b)\n",
        "  b = abc(hidden_dim=1024)([b,d_b,b])\n",
        "  b = LayerNormalization()(b)\n",
        "  b = Reshape((14,14,1024,))(b)\n",
        "  b = keras.layers.GlobalAveragePooling2D()(b)\n",
        "\n",
        "  d = keras.layers.GlobalAveragePooling2D()(d)\n",
        "  \n",
        "\n",
        "  b = Dense(3, activation=\"softmax\")(b) \n",
        "  b = Reshape((-1,3))(b) \n",
        "  a = Dense(3, activation=\"softmax\")(a) \n",
        "  a = Reshape((-1,3))(a) \n",
        "  d = Dense(3, activation=\"softmax\")(d) \n",
        "  d = Reshape((-1,3))(d) \n",
        "  \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "#   mod.load_weights('../input/global-3535-fold-1-1/weights.hdf5')\n",
        "#   for layer in mod.layers:\n",
        "#     layer.trainable=False\n",
        "  a=mod.layers[-9].output\n",
        "  b=mod.layers[-10].output\n",
        "  d=mod.layers[-11].output\n",
        "  b = Dense(1, activation=\"sigmoid\")(b) \n",
        "  b = Reshape((-1,1))(b) \n",
        "  a = Dense(1, activation=\"sigmoid\")(a) \n",
        "  a = Reshape((-1,1))(a) \n",
        "  d = Dense(1, activation=\"sigmoid\")(d) \n",
        "  d = Reshape((-1,1))(d) \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  return mod\n",
        "\n",
        "mod=load_model()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFOM3uzSR-0W"
      },
      "source": [
        "\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle))\n",
        "    return ls\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=np.repeat(labels,9)\n",
        "    del([imgV,imgR,imgH,lbl])\n",
        "    gc.collect()\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return np.asarray(images).astype('float16'), labels.astype('uint8')\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSYryIU3SAHd",
        "outputId": "3438e8ba-8ea8-47eb-aa90-f96ca64ded68"
      },
      "source": [
        "import cv2\n",
        "import gc\n",
        "from tensorflow.keras.optimizers import *\n",
        "train_data = DataGenerator(X_train,y_train, batch_size=4, augment=True)\n",
        "mod.compile(optimizer=Adam(4e-5,decay=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "hist=mod.fit_generator(train_data,epochs=50)\n",
        "gc.collect()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "81/81 [==============================] - 45s 351ms/step - loss: 0.7058 - accuracy: 0.5134\n",
            "Epoch 2/50\n",
            "81/81 [==============================] - 29s 351ms/step - loss: 0.6898 - accuracy: 0.5401\n",
            "Epoch 3/50\n",
            "81/81 [==============================] - 29s 351ms/step - loss: 0.6838 - accuracy: 0.5487\n",
            "Epoch 4/50\n",
            "81/81 [==============================] - 29s 351ms/step - loss: 0.6799 - accuracy: 0.5600\n",
            "Epoch 5/50\n",
            "81/81 [==============================] - 29s 352ms/step - loss: 0.6710 - accuracy: 0.5943\n",
            "Epoch 6/50\n",
            "81/81 [==============================] - 28s 346ms/step - loss: 0.6509 - accuracy: 0.6200\n",
            "Epoch 7/50\n",
            "81/81 [==============================] - 28s 344ms/step - loss: 0.6282 - accuracy: 0.6701\n",
            "Epoch 8/50\n",
            "81/81 [==============================] - 28s 341ms/step - loss: 0.6144 - accuracy: 0.6989\n",
            "Epoch 9/50\n",
            "81/81 [==============================] - 28s 345ms/step - loss: 0.5407 - accuracy: 0.7469\n",
            "Epoch 10/50\n",
            "81/81 [==============================] - 29s 351ms/step - loss: 0.5174 - accuracy: 0.7678\n",
            "Epoch 11/50\n",
            "81/81 [==============================] - 29s 350ms/step - loss: 0.4388 - accuracy: 0.8368\n",
            "Epoch 12/50\n",
            "81/81 [==============================] - 29s 350ms/step - loss: 0.4070 - accuracy: 0.8628\n",
            "Epoch 13/50\n",
            "81/81 [==============================] - 29s 350ms/step - loss: 0.3616 - accuracy: 0.8968\n",
            "Epoch 14/50\n",
            "81/81 [==============================] - 29s 350ms/step - loss: 0.3208 - accuracy: 0.9235\n",
            "Epoch 15/50\n",
            "81/81 [==============================] - 29s 350ms/step - loss: 0.3159 - accuracy: 0.9235\n",
            "Epoch 16/50\n",
            "81/81 [==============================] - 29s 350ms/step - loss: 0.3161 - accuracy: 0.9005\n",
            "Epoch 17/50\n",
            "81/81 [==============================] - 29s 351ms/step - loss: 0.3508 - accuracy: 0.8385\n",
            "Epoch 18/50\n",
            "81/81 [==============================] - 29s 350ms/step - loss: 0.2528 - accuracy: 0.8978\n",
            "Epoch 19/50\n",
            "81/81 [==============================] - 29s 350ms/step - loss: 0.1456 - accuracy: 0.9434\n",
            "Epoch 20/50\n",
            "81/81 [==============================] - 29s 349ms/step - loss: 0.0912 - accuracy: 0.9705\n",
            "Epoch 21/50\n",
            "81/81 [==============================] - 29s 349ms/step - loss: 0.0731 - accuracy: 0.9757\n",
            "Epoch 22/50\n",
            "81/81 [==============================] - 28s 347ms/step - loss: 0.0588 - accuracy: 0.9842\n",
            "Epoch 23/50\n",
            "81/81 [==============================] - 28s 340ms/step - loss: 0.0703 - accuracy: 0.9763\n",
            "Epoch 24/50\n",
            "81/81 [==============================] - 28s 341ms/step - loss: 0.0618 - accuracy: 0.9784\n",
            "Epoch 25/50\n",
            "81/81 [==============================] - 28s 338ms/step - loss: 0.0670 - accuracy: 0.9763\n",
            "Epoch 26/50\n",
            "81/81 [==============================] - 27s 337ms/step - loss: 0.1196 - accuracy: 0.9544\n",
            "Epoch 27/50\n",
            "81/81 [==============================] - 28s 340ms/step - loss: 0.1316 - accuracy: 0.9537\n",
            "Epoch 28/50\n",
            "81/81 [==============================] - 28s 343ms/step - loss: 0.0651 - accuracy: 0.9770\n",
            "Epoch 29/50\n",
            "81/81 [==============================] - 28s 346ms/step - loss: 0.0355 - accuracy: 0.9894\n",
            "Epoch 30/50\n",
            "81/81 [==============================] - 28s 348ms/step - loss: 0.0262 - accuracy: 0.9911\n",
            "Epoch 31/50\n",
            "81/81 [==============================] - 29s 354ms/step - loss: 0.0226 - accuracy: 0.9925\n",
            "Epoch 32/50\n",
            "81/81 [==============================] - 29s 350ms/step - loss: 0.0155 - accuracy: 0.9935\n",
            "Epoch 33/50\n",
            "81/81 [==============================] - 29s 349ms/step - loss: 0.0140 - accuracy: 0.9935\n",
            "Epoch 34/50\n",
            "81/81 [==============================] - 29s 349ms/step - loss: 0.0130 - accuracy: 0.9935\n",
            "Epoch 35/50\n",
            "81/81 [==============================] - 28s 349ms/step - loss: 0.0122 - accuracy: 0.9935\n",
            "Epoch 36/50\n",
            "81/81 [==============================] - 28s 348ms/step - loss: 0.0115 - accuracy: 0.9935\n",
            "Epoch 37/50\n",
            "81/81 [==============================] - 28s 348ms/step - loss: 0.0110 - accuracy: 0.9935\n",
            "Epoch 38/50\n",
            "81/81 [==============================] - 28s 347ms/step - loss: 0.0106 - accuracy: 0.9935\n",
            "Epoch 39/50\n",
            "81/81 [==============================] - 29s 349ms/step - loss: 0.0102 - accuracy: 0.9935\n",
            "Epoch 40/50\n",
            "81/81 [==============================] - 28s 348ms/step - loss: 0.0099 - accuracy: 0.9935\n",
            "Epoch 41/50\n",
            "81/81 [==============================] - 28s 349ms/step - loss: 0.0096 - accuracy: 0.9935\n",
            "Epoch 42/50\n",
            "81/81 [==============================] - 29s 350ms/step - loss: 0.0094 - accuracy: 0.9935\n",
            "Epoch 43/50\n",
            "81/81 [==============================] - 28s 338ms/step - loss: 0.0092 - accuracy: 0.9935\n",
            "Epoch 44/50\n",
            "81/81 [==============================] - 28s 337ms/step - loss: 0.0090 - accuracy: 0.9935\n",
            "Epoch 45/50\n",
            "81/81 [==============================] - 28s 339ms/step - loss: 0.0088 - accuracy: 0.9935\n",
            "Epoch 46/50\n",
            "81/81 [==============================] - 28s 338ms/step - loss: 0.0087 - accuracy: 0.9935\n",
            "Epoch 47/50\n",
            "81/81 [==============================] - 27s 336ms/step - loss: 0.0086 - accuracy: 0.9935\n",
            "Epoch 48/50\n",
            "81/81 [==============================] - 28s 337ms/step - loss: 0.0084 - accuracy: 0.9935\n",
            "Epoch 49/50\n",
            "81/81 [==============================] - 28s 338ms/step - loss: 0.0083 - accuracy: 0.9935\n",
            "Epoch 50/50\n",
            "81/81 [==============================] - 27s 336ms/step - loss: 0.0082 - accuracy: 0.9935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "cQsjaFpnSCYF",
        "outputId": "5154afe5-5cce-4b7d-8853-b9ae6e468942"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(hist.history['loss'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd28625ced0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chueipcfamB1",
        "outputId": "2196b529-1d48-4bda-d6cd-ce2da8ade261"
      },
      "source": [
        "pre=mod.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(np.round(pre),y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5900621118012422"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmL7qZBdasw4"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}