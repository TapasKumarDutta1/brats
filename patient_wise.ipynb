{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "patient_wise.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPgrOcWSWoCbgw4Iz1VS/Hd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/brats/blob/main/patient_wise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmEVAnnI7A4V"
      },
      "source": [
        "pip install medpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOUTNSey7DtB"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from medpy.io import load, save\n",
        "import numpy as np\n",
        "import gc\n",
        "import cv2\n",
        "import glob\n",
        "target_dict={'HGG':1,'LGG':0}\n",
        "targets_h=[]\n",
        "images_h=[]\n",
        "for path in tqdm(glob.glob('../input/brain-tumor-segmentation-brats-2019/MICCAI_BraTS_2019_Data_Training/HGG/*/*_flair.nii')):\n",
        "    trg=path.split('/')\n",
        "    img=load(path)[0]\n",
        "    seg=load(path.replace('_flair','_seg'))[0]\n",
        "    mn=np.mean(img)\n",
        "    std=np.std(img)\n",
        "    try:\n",
        "        pos=round((min(np.where(seg==1)[-1])+max(np.where(seg==1)[-1]))/2)\n",
        "        img=cv2.resize(img[:,:,pos], (224,224), interpolation = cv2.INTER_AREA )\n",
        "        img=(img-mn)/std\n",
        "        img=np.repeat(np.expand_dims(img,-1),3,-1)\n",
        "        images_h.append(img)\n",
        "        targets_h.append(target_dict[path.split('/')[4]])\n",
        "        del([img,seg])\n",
        "        gc.collect()\n",
        "    except:\n",
        "        continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeQ1OVDJ7DqL"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from medpy.io import load, save\n",
        "import numpy as np\n",
        "import gc\n",
        "import cv2\n",
        "import glob\n",
        "target_dict={'HGG':1,'LGG':0}\n",
        "targets_l=[]\n",
        "images_l=[]\n",
        "for path in tqdm(glob.glob('../input/brain-tumor-segmentation-brats-2019/MICCAI_BraTS_2019_Data_Training/LGG/*/*_flair.nii')):\n",
        "    image=np.zeros((224,224,9))\n",
        "    trg=path.split('/')\n",
        "    original=load(path)[0]\n",
        "    seg=load(path.replace('_flair','_seg'))[0]\n",
        "    mn=np.mean(original)\n",
        "    std=np.std(original)\n",
        "    try:\n",
        "        pos=round((min(np.where(seg==1)[-1])+max(np.where(seg==1)[-1]))/2)\n",
        "        dev=np.std(list(range(original.shape[-1])))*0.08\n",
        "        \n",
        "        img=cv2.resize(original[:,:,pos+int(dev)], (224,224), interpolation = cv2.INTER_AREA )\n",
        "        img=(img-mn)/std\n",
        "        img=np.repeat(np.expand_dims(img,-1),3,-1)\n",
        "        image[:,:,:3]=img\n",
        "        targets_l.append(target_dict[path.split('/')[4]])\n",
        "        \n",
        "        img=cv2.resize(original[:,:,pos-int(dev)], (224,224), interpolation = cv2.INTER_AREA )\n",
        "        img=(img-mn)/std\n",
        "        img=np.repeat(np.expand_dims(img,-1),3,-1)\n",
        "        image[:,:,3:6]=img\n",
        "        \n",
        "        \n",
        "        img=cv2.resize(original[:,:,pos], (224,224), interpolation = cv2.INTER_AREA )\n",
        "        img=(img-mn)/std\n",
        "        img=np.repeat(np.expand_dims(img,-1),3,-1)\n",
        "        image[:,:,6:9]=img\n",
        "        images_l.append(image)\n",
        "        \n",
        "        del([img,seg])\n",
        "        gc.collect()\n",
        "    except:\n",
        "        continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIcdB6UA7DnD"
      },
      "source": [
        "\n",
        "\n",
        "targets=targets_h+targets_l\n",
        "targets=np.array(targets)\n",
        "\n",
        "np.save('targets_h.npy',targets_h)\n",
        "np.save('targets_l.npy',targets_l)\n",
        "np.save('images_h.npy',images_h)\n",
        "np.save('images_l.npy',images_l)\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self.eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "class abc(keras.layers.Layer):\n",
        "    def __init__(self,\n",
        "                 hidden_dim,\n",
        "                 **kwargs):\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.conv1=Conv1D(self.hidden_dim,1)\n",
        "        self.conv2=Conv1D(self.hidden_dim,1)\n",
        "        self.conv3=Conv1D(self.hidden_dim,1)\n",
        "        \n",
        "        self.Wq = self.Wk = self.Wv = self.Wo = None\n",
        "        self.bq = self.bk = self.bv = self.bo = None\n",
        "\n",
        "        self.intensity = self.attention = None\n",
        "        super(abc, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        \n",
        "        q, k, v = inputs\n",
        "        \n",
        "        q=self.conv1(q)\n",
        "        k=self.conv2(k)\n",
        "        v=self.conv3(v)\n",
        "        \n",
        "        \n",
        "        def scaled_dot_product_attention(inputs):\n",
        "          query, key, value = inputs\n",
        "          feature_dim = K.shape(query)[-1]\n",
        "          e = K.batch_dot(query, key, axes=2) \n",
        "          intensity = e\n",
        "          e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
        "          attention = e / K.sum(e, axis=-1, keepdims=True)\n",
        "          v = K.batch_dot(attention, value)\n",
        "          return v\n",
        "       \n",
        "       \n",
        "        y = scaled_dot_product_attention(inputs=[q,k,v])\n",
        "        \n",
        "        \n",
        "        return y\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import *\n",
        "def load_model():   \n",
        "  \n",
        "  K.clear_session() \n",
        "  mod=densenet.DenseNet121(include_top=True, weights='imagenet')\n",
        "  d = mod.get_layer('conv5_block16_concat').output\n",
        "\n",
        "  inp = mod.get_layer('conv3_block12_concat').output\n",
        "  a = Reshape((28*28,512))(inp)\n",
        "  d_a = keras.layers.UpSampling2D(interpolation='bilinear',size=(4,4))(d)\n",
        "  d_a = Reshape((28*28,1024))(d_a)\n",
        "  a = abc(hidden_dim=512)([a,d_a,a])\n",
        "  a = LayerNormalization()(a)\n",
        "  a = Reshape((28,28,512,))(a)\n",
        "  a = keras.layers.GlobalAveragePooling2D()(a)\n",
        "\n",
        "  inp = mod.get_layer('conv4_block24_concat').output\n",
        "  b = Reshape((14*14,1024))(inp)\n",
        "  d_b = keras.layers.UpSampling2D(interpolation='bilinear',size=(2,2))(d)\n",
        "  d_b = Reshape((14*14,1024))(d_b)\n",
        "  b = abc(hidden_dim=1024)([b,d_b,b])\n",
        "  b = LayerNormalization()(b)\n",
        "  b = Reshape((14,14,1024,))(b)\n",
        "  b = keras.layers.GlobalAveragePooling2D()(b)\n",
        "\n",
        "  d = keras.layers.GlobalAveragePooling2D()(d)\n",
        "  \n",
        "\n",
        "  b = Dense(3, activation=\"softmax\")(b) \n",
        "  b = Reshape((-1,3))(b) \n",
        "  a = Dense(3, activation=\"softmax\")(a) \n",
        "  a = Reshape((-1,3))(a) \n",
        "  d = Dense(3, activation=\"softmax\")(d) \n",
        "  d = Reshape((-1,3))(d) \n",
        "  \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  mod.load_weights('../input/attention/weights.hdf5')\n",
        "  for layer in mod.layers:\n",
        "    layer.trainable=False\n",
        "  a=mod.layers[-9].output\n",
        "  b=mod.layers[-10].output\n",
        "  d=mod.layers[-11].output\n",
        "  b = Dense(1, activation=\"sigmoid\")(b) \n",
        "  b = Reshape((-1,1))(b) \n",
        "  a = Dense(1, activation=\"sigmoid\")(a) \n",
        "  a = Reshape((-1,1))(a) \n",
        "  d = Dense(1, activation=\"sigmoid\")(d) \n",
        "  d = Reshape((-1,1))(d) \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  for en,layer in enumerate(mod.layers):\n",
        "    if layer.trainable==True:\n",
        "        print(en)\n",
        "  return mod\n",
        "\n",
        "mod=load_model()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkvq3fvS7DkH"
      },
      "source": [
        "\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle))\n",
        "    return ls\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=np.repeat(labels,9)\n",
        "    del([imgV,imgR,imgH,lbl])\n",
        "    gc.collect()\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return np.asarray(images).astype('float64'), labels.astype('uint8')\n",
        "\n",
        "import cv2\n",
        "import gc\n",
        "from tensorflow.keras.optimizers import *\n",
        "from sklearn.model_selection import *\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "kf=KFold(n_splits=5)\n",
        "for train_index, test_index in kf.split(targets):\n",
        "  mod=load_model()  \n",
        "  X_train, X_test, y_train, y_test = [],[],[],[]\n",
        "  for i in train_index:\n",
        "    if i<len(targets_h):\n",
        "        X_train.append(images_h[i])\n",
        "        y_train.append(1)\n",
        "    else:\n",
        "        X_train.append(images_l[i-len(targets_h)][:,:,:3])\n",
        "        X_train.append(images_l[i-len(targets_h)][:,:,3:6])\n",
        "        X_train.append(images_l[i-len(targets_h)][:,:,6:9])\n",
        "        y_train.extend([0,0,0])\n",
        "  for i in test_index:\n",
        "    if i<len(targets_h):\n",
        "        X_test.append(images_h[i])\n",
        "        y_test.append(1)\n",
        "    else:\n",
        "        X_test.append(images_l[i-len(targets_h)][:,:,:3])\n",
        "        X_test.append(images_l[i-len(targets_h)][:,:,3:6])\n",
        "        X_test.append(images_l[i-len(targets_h)][:,:,6:9])\n",
        "        y_test.extend([0,0,0])\n",
        "  X_train=np.asarray(X_train)\n",
        "  X_test=np.asarray(X_test)\n",
        "  y_train=np.asarray(y_train)\n",
        "  y_test=np.asarray(y_test)\n",
        "  print(X_train.shape, X_test.shape,y_train.shape,y_test.shape)\n",
        "  train_data = DataGenerator(X_train,y_train, batch_size=4, augment=True)\n",
        "  mod.compile(optimizer=Adam(5e-5,decay=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  print('started training')\n",
        "  hist=mod.fit_generator(train_data,epochs=50,verbose=0)\n",
        "  plt.plot(hist.history['loss'])\n",
        "  plt.show()\n",
        "  pre=mod.predict(X_test)\n",
        "  print(accuracy_score(np.round(pre),y_test))\n",
        "  del([mod,X_train, X_test, y_train, y_test,train_data])\n",
        "  gc.collect()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWfJ-O7a7DhD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VvA1_117DeH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL8GVQKZ7DbG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}