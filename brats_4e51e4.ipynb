{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brats_4e51e4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPURqMTs4vdouWZtrEhCLf0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/brats/blob/main/brats_4e51e4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BE8ybeW8ohO",
        "outputId": "d9655bb1-60a1-45a0-b338-84e27be6c323"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH28Ai7h8sKd",
        "outputId": "5044c3ee-ce31-499e-d063-18d5b6734248"
      },
      "source": [
        "pip install medpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: medpy in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.19.5)\n",
            "Requirement already satisfied: SimpleITK>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (2.0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b41zmYl81Sb"
      },
      "source": [
        "import numpy as np\n",
        "images=np.load('/content/gdrive/MyDrive/Brats2d/images.npy')\n",
        "targets=np.load('/content/gdrive/MyDrive/Brats2d/targets.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUjMFxZE8zC4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images,targets, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp7oJ7Jw8_ZO"
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self.eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "class abc(keras.layers.Layer):\n",
        "    def __init__(self,\n",
        "                 hidden_dim,\n",
        "                 **kwargs):\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.conv1=Conv1D(self.hidden_dim,1)\n",
        "        self.conv2=Conv1D(self.hidden_dim,1)\n",
        "        self.conv3=Conv1D(self.hidden_dim,1)\n",
        "        \n",
        "        self.Wq = self.Wk = self.Wv = self.Wo = None\n",
        "        self.bq = self.bk = self.bv = self.bo = None\n",
        "\n",
        "        self.intensity = self.attention = None\n",
        "        super(abc, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        \n",
        "        q, k, v = inputs\n",
        "        \n",
        "        q=self.conv1(q)\n",
        "        k=self.conv2(k)\n",
        "        v=self.conv3(v)\n",
        "        \n",
        "        \n",
        "        def scaled_dot_product_attention(inputs):\n",
        "          query, key, value = inputs\n",
        "          feature_dim = K.shape(query)[-1]\n",
        "          e = K.batch_dot(query, key, axes=2) \n",
        "          intensity = e\n",
        "          e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
        "          attention = e / K.sum(e, axis=-1, keepdims=True)\n",
        "          v = K.batch_dot(attention, value)\n",
        "          return v\n",
        "       \n",
        "       \n",
        "        y = scaled_dot_product_attention(inputs=[q,k,v])\n",
        "        \n",
        "        \n",
        "        return y\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import *\n",
        "def load_model():   \n",
        "  \n",
        "  K.clear_session() \n",
        "  mod=densenet.DenseNet121(include_top=True, weights='imagenet')\n",
        "  d = mod.get_layer('conv5_block16_concat').output\n",
        "\n",
        "  inp = mod.get_layer('conv3_block12_concat').output\n",
        "  a = Reshape((28*28,512))(inp)\n",
        "  d_a = keras.layers.UpSampling2D(interpolation='bilinear',size=(4,4))(d)\n",
        "  d_a = Reshape((28*28,1024))(d_a)\n",
        "  a = abc(hidden_dim=512)([a,d_a,a])\n",
        "  a = LayerNormalization()(a)\n",
        "  a = Reshape((28,28,512,))(a)\n",
        "  a = keras.layers.GlobalAveragePooling2D()(a)\n",
        "\n",
        "  inp = mod.get_layer('conv4_block24_concat').output\n",
        "  b = Reshape((14*14,1024))(inp)\n",
        "  d_b = keras.layers.UpSampling2D(interpolation='bilinear',size=(2,2))(d)\n",
        "  d_b = Reshape((14*14,1024))(d_b)\n",
        "  b = abc(hidden_dim=1024)([b,d_b,b])\n",
        "  b = LayerNormalization()(b)\n",
        "  b = Reshape((14,14,1024,))(b)\n",
        "  b = keras.layers.GlobalAveragePooling2D()(b)\n",
        "\n",
        "  d = keras.layers.GlobalAveragePooling2D()(d)\n",
        "  \n",
        "\n",
        "  b = Dense(3, activation=\"softmax\")(b) \n",
        "  b = Reshape((-1,3))(b) \n",
        "  a = Dense(3, activation=\"softmax\")(a) \n",
        "  a = Reshape((-1,3))(a) \n",
        "  d = Dense(3, activation=\"softmax\")(d) \n",
        "  d = Reshape((-1,3))(d) \n",
        "  \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  # mod.load_weights('../input/global-3535-fold-1-1/weights.hdf5')\n",
        "  # for layer in mod.layers:\n",
        "  #   layer.trainable=False\n",
        "  a=mod.layers[-9].output\n",
        "  b=mod.layers[-10].output\n",
        "  d=mod.layers[-11].output\n",
        "  b = Dense(1, activation=\"sigmoid\")(b) \n",
        "  b = Reshape((-1,1))(b) \n",
        "  a = Dense(1, activation=\"sigmoid\")(a) \n",
        "  a = Reshape((-1,1))(a) \n",
        "  d = Dense(1, activation=\"sigmoid\")(d) \n",
        "  d = Reshape((-1,1))(d) \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  return mod\n",
        "\n",
        "mod=load_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4t7V-e99Eg-"
      },
      "source": [
        "\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle))\n",
        "    return ls\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=np.repeat(labels,9)\n",
        "    del([imgV,imgR,imgH,lbl])\n",
        "    gc.collect()\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return np.asarray(images).astype('float16'), labels.astype('uint8')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UulC6f8x9GyG",
        "outputId": "9ae59501-f430-41ab-8339-82a5dc1cd118"
      },
      "source": [
        "import cv2\n",
        "import gc\n",
        "from tensorflow.keras.optimizers import *\n",
        "train_data = DataGenerator(X_train,y_train, batch_size=4, augment=True)\n",
        "mod.compile(optimizer=Adam(4e-5,decay=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "hist=mod.fit_generator(train_data,epochs=50)\n",
        "gc.collect()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "81/81 [==============================] - 67s 610ms/step - loss: 0.7224 - accuracy: 0.4664\n",
            "Epoch 2/50\n",
            "81/81 [==============================] - 48s 592ms/step - loss: 0.6889 - accuracy: 0.5566\n",
            "Epoch 3/50\n",
            "81/81 [==============================] - 49s 600ms/step - loss: 0.6825 - accuracy: 0.5576\n",
            "Epoch 4/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.6767 - accuracy: 0.5868\n",
            "Epoch 5/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.6629 - accuracy: 0.6125\n",
            "Epoch 6/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.6409 - accuracy: 0.6372\n",
            "Epoch 7/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.6146 - accuracy: 0.6650\n",
            "Epoch 8/50\n",
            "81/81 [==============================] - 50s 608ms/step - loss: 0.5524 - accuracy: 0.7233\n",
            "Epoch 9/50\n",
            "81/81 [==============================] - 49s 606ms/step - loss: 0.4682 - accuracy: 0.7922\n",
            "Epoch 10/50\n",
            "81/81 [==============================] - 48s 591ms/step - loss: 0.4390 - accuracy: 0.8265\n",
            "Epoch 11/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.3953 - accuracy: 0.8604\n",
            "Epoch 12/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.3511 - accuracy: 0.8930\n",
            "Epoch 13/50\n",
            "81/81 [==============================] - 49s 596ms/step - loss: 0.3248 - accuracy: 0.8923\n",
            "Epoch 14/50\n",
            "81/81 [==============================] - 49s 597ms/step - loss: 0.2986 - accuracy: 0.8889\n",
            "Epoch 15/50\n",
            "81/81 [==============================] - 49s 596ms/step - loss: 0.2632 - accuracy: 0.8927\n",
            "Epoch 16/50\n",
            "81/81 [==============================] - 49s 597ms/step - loss: 0.2173 - accuracy: 0.9170\n",
            "Epoch 17/50\n",
            "81/81 [==============================] - 49s 597ms/step - loss: 0.1494 - accuracy: 0.9537\n",
            "Epoch 18/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.1150 - accuracy: 0.9674\n",
            "Epoch 19/50\n",
            "81/81 [==============================] - 49s 596ms/step - loss: 0.0787 - accuracy: 0.9791\n",
            "Epoch 20/50\n",
            "81/81 [==============================] - 49s 597ms/step - loss: 0.0545 - accuracy: 0.9873\n",
            "Epoch 21/50\n",
            "81/81 [==============================] - 49s 599ms/step - loss: 0.0470 - accuracy: 0.9925\n",
            "Epoch 22/50\n",
            "81/81 [==============================] - 49s 608ms/step - loss: 0.0362 - accuracy: 0.9938\n",
            "Epoch 23/50\n",
            "81/81 [==============================] - 48s 590ms/step - loss: 0.0341 - accuracy: 0.9928\n",
            "Epoch 24/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.0823 - accuracy: 0.9739\n",
            "Epoch 25/50\n",
            "81/81 [==============================] - 48s 593ms/step - loss: 0.1018 - accuracy: 0.9691\n",
            "Epoch 26/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.1643 - accuracy: 0.9427\n",
            "Epoch 27/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.0824 - accuracy: 0.9767\n",
            "Epoch 28/50\n",
            "81/81 [==============================] - 49s 597ms/step - loss: 0.0700 - accuracy: 0.9818\n",
            "Epoch 29/50\n",
            "81/81 [==============================] - 49s 596ms/step - loss: 0.0561 - accuracy: 0.9849\n",
            "Epoch 30/50\n",
            "81/81 [==============================] - 49s 596ms/step - loss: 0.0417 - accuracy: 0.9918\n",
            "Epoch 31/50\n",
            "81/81 [==============================] - 49s 597ms/step - loss: 0.0351 - accuracy: 0.9918\n",
            "Epoch 32/50\n",
            "81/81 [==============================] - 49s 597ms/step - loss: 0.0224 - accuracy: 0.9949\n",
            "Epoch 33/50\n",
            "81/81 [==============================] - 49s 598ms/step - loss: 0.0168 - accuracy: 0.9962\n",
            "Epoch 34/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0150 - accuracy: 0.9962\n",
            "Epoch 35/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0136 - accuracy: 0.9962\n",
            "Epoch 36/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0126 - accuracy: 0.9962\n",
            "Epoch 37/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0119 - accuracy: 0.9962\n",
            "Epoch 38/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0112 - accuracy: 0.9962\n",
            "Epoch 39/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0107 - accuracy: 0.9962\n",
            "Epoch 40/50\n",
            "81/81 [==============================] - 49s 596ms/step - loss: 0.0103 - accuracy: 0.9962\n",
            "Epoch 41/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0099 - accuracy: 0.9962\n",
            "Epoch 42/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0096 - accuracy: 0.9962\n",
            "Epoch 43/50\n",
            "81/81 [==============================] - 49s 597ms/step - loss: 0.0094 - accuracy: 0.9962\n",
            "Epoch 44/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0091 - accuracy: 0.9962\n",
            "Epoch 45/50\n",
            "81/81 [==============================] - 49s 596ms/step - loss: 0.0089 - accuracy: 0.9962\n",
            "Epoch 46/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0088 - accuracy: 0.9962\n",
            "Epoch 47/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0086 - accuracy: 0.9962\n",
            "Epoch 48/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0085 - accuracy: 0.9962\n",
            "Epoch 49/50\n",
            "81/81 [==============================] - 48s 595ms/step - loss: 0.0083 - accuracy: 0.9962\n",
            "Epoch 50/50\n",
            "81/81 [==============================] - 48s 596ms/step - loss: 0.0082 - accuracy: 0.9962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD0ya6rDBGjB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "754d47ac-9161-4c10-883f-d5e7b735aa9b"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(hist.history['loss'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5cd00b5090>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1MYbBZvaZBI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50bbf552-1444-4983-e5c2-db72e03b8423"
      },
      "source": [
        "pre=mod.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(np.round(pre),y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6459627329192547"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6iKXL47apzO"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    }
  ]
}