{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5F_brats_5e51e4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPPlF0syUW8Cd3MHc2sTNq5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/brats/blob/main/5F_brats_5e51e4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BE8ybeW8ohO",
        "outputId": "023d953d-9f3d-42da-9a8f-bdf6e988cba9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH28Ai7h8sKd",
        "outputId": "8137695c-3a83-47e4-a545-28b4856d60b6"
      },
      "source": [
        "pip install medpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting medpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/70/c1fd5dd60242eee81774696ea7ba4caafac2bad8f028bba94b1af83777d7/MedPy-0.4.0.tar.gz (151kB)\n",
            "\r\u001b[K     |██▏                             | 10kB 17.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20kB 22.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 30kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 40kB 17.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 51kB 13.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 61kB 10.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 71kB 11.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 81kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 92kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 102kB 12.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 112kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 122kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 133kB 12.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 143kB 12.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.19.5)\n",
            "Collecting SimpleITK>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/6b/85df5eb3a8059b23a53a9f224476e75473f9bcc0a8583ed1a9c34619f372/SimpleITK-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (47.4MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4MB 65kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: medpy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b41zmYl81Sb"
      },
      "source": [
        "import numpy as np\n",
        "images=np.load('/content/gdrive/MyDrive/Brats2d/images.npy')\n",
        "targets=np.load('/content/gdrive/MyDrive/Brats2d/targets.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp7oJ7Jw8_ZO"
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self.eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "class abc(keras.layers.Layer):\n",
        "    def __init__(self,\n",
        "                 hidden_dim,\n",
        "                 **kwargs):\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.conv1=Conv1D(self.hidden_dim,1)\n",
        "        self.conv2=Conv1D(self.hidden_dim,1)\n",
        "        self.conv3=Conv1D(self.hidden_dim,1)\n",
        "        \n",
        "        self.Wq = self.Wk = self.Wv = self.Wo = None\n",
        "        self.bq = self.bk = self.bv = self.bo = None\n",
        "\n",
        "        self.intensity = self.attention = None\n",
        "        super(abc, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        \n",
        "        q, k, v = inputs\n",
        "        \n",
        "        q=self.conv1(q)\n",
        "        k=self.conv2(k)\n",
        "        v=self.conv3(v)\n",
        "        \n",
        "        \n",
        "        def scaled_dot_product_attention(inputs):\n",
        "          query, key, value = inputs\n",
        "          feature_dim = K.shape(query)[-1]\n",
        "          e = K.batch_dot(query, key, axes=2) \n",
        "          intensity = e\n",
        "          e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
        "          attention = e / K.sum(e, axis=-1, keepdims=True)\n",
        "          v = K.batch_dot(attention, value)\n",
        "          return v\n",
        "       \n",
        "       \n",
        "        y = scaled_dot_product_attention(inputs=[q,k,v])\n",
        "        \n",
        "        \n",
        "        return y\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import *\n",
        "def load_model():   \n",
        "  \n",
        "  K.clear_session() \n",
        "  mod=densenet.DenseNet121(include_top=True, weights='imagenet')\n",
        "  d = mod.get_layer('conv5_block16_concat').output\n",
        "\n",
        "  inp = mod.get_layer('conv3_block12_concat').output\n",
        "  a = Reshape((28*28,512))(inp)\n",
        "  d_a = keras.layers.UpSampling2D(interpolation='bilinear',size=(4,4))(d)\n",
        "  d_a = Reshape((28*28,1024))(d_a)\n",
        "  a = abc(hidden_dim=512)([a,d_a,a])\n",
        "  a = LayerNormalization()(a)\n",
        "  a = Reshape((28,28,512,))(a)\n",
        "  a = keras.layers.GlobalAveragePooling2D()(a)\n",
        "\n",
        "  inp = mod.get_layer('conv4_block24_concat').output\n",
        "  b = Reshape((14*14,1024))(inp)\n",
        "  d_b = keras.layers.UpSampling2D(interpolation='bilinear',size=(2,2))(d)\n",
        "  d_b = Reshape((14*14,1024))(d_b)\n",
        "  b = abc(hidden_dim=1024)([b,d_b,b])\n",
        "  b = LayerNormalization()(b)\n",
        "  b = Reshape((14,14,1024,))(b)\n",
        "  b = keras.layers.GlobalAveragePooling2D()(b)\n",
        "\n",
        "  d = keras.layers.GlobalAveragePooling2D()(d)\n",
        "  \n",
        "\n",
        "  b = Dense(3, activation=\"softmax\")(b) \n",
        "  b = Reshape((-1,3))(b) \n",
        "  a = Dense(3, activation=\"softmax\")(a) \n",
        "  a = Reshape((-1,3))(a) \n",
        "  d = Dense(3, activation=\"softmax\")(d) \n",
        "  d = Reshape((-1,3))(d) \n",
        "  \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  # mod.load_weights('../input/global-3535-fold-1-1/weights.hdf5')\n",
        "  # for layer in mod.layers:\n",
        "  #   layer.trainable=False\n",
        "  a=mod.layers[-9].output\n",
        "  b=mod.layers[-10].output\n",
        "  d=mod.layers[-11].output\n",
        "  b = Dense(1, activation=\"sigmoid\")(b) \n",
        "  b = Reshape((-1,1))(b) \n",
        "  a = Dense(1, activation=\"sigmoid\")(a) \n",
        "  a = Reshape((-1,1))(a) \n",
        "  d = Dense(1, activation=\"sigmoid\")(d) \n",
        "  d = Reshape((-1,1))(d) \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  return mod\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4t7V-e99Eg-"
      },
      "source": [
        "\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle))\n",
        "    return ls\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=np.repeat(labels,9)\n",
        "    del([imgV,imgR,imgH,lbl])\n",
        "    gc.collect()\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return np.asarray(images).astype('float16'), labels.astype('uint8')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UulC6f8x9GyG"
      },
      "source": [
        "import cv2\n",
        "import gc\n",
        "from tensorflow.keras.optimizers import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "kf=KFold(n_splits=5, random_state=42, shuffle=False)\n",
        "for train_index, test_index in kf.split(targets):\n",
        "  mod=load_model()\n",
        "  X_train, X_test, y_train, y_test = images[train_index],images[test_index],targets[train_index],targets[test_index]\n",
        "  train_data = DataGenerator(X_train,y_train, batch_size=4, augment=True)\n",
        "  mod.compile(optimizer=Adam(5e-5,decay=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  hist=mod.fit_generator(train_data,epochs=50)\n",
        "  del([mod,X_train, X_test, y_train, y_test,train_data])\n",
        "  gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD0ya6rDBGjB"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(hist.history['loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1MYbBZvaZBI"
      },
      "source": [
        "pre=mod.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(np.round(pre),y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6iKXL47apzO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}