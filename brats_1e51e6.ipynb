{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brats_1e51e6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP59C62bb/8pSdNTH7LREik",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/brats/blob/main/brats_1e51e6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BE8ybeW8ohO",
        "outputId": "58aaa125-bfd8-464f-9ada-1b451d887925"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH28Ai7h8sKd",
        "outputId": "b12f20bd-da74-4db5-aa1f-653c2b4277a0"
      },
      "source": [
        "pip install medpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: medpy in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.19.5)\n",
            "Requirement already satisfied: SimpleITK>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b41zmYl81Sb"
      },
      "source": [
        "import numpy as np\n",
        "images=np.load('/content/gdrive/MyDrive/Brats2d/images.npy')\n",
        "targets=np.load('/content/gdrive/MyDrive/Brats2d/targets.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUjMFxZE8zC4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(images,targets, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp7oJ7Jw8_ZO"
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import random, os, sys\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.initializers import *\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "class LayerNormalization(Layer):\n",
        "    def __init__(self, eps=1e-6, **kwargs):\n",
        "        self.eps = eps\n",
        "        super(LayerNormalization, self).__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(name='gamma', shape=input_shape[-1:],\n",
        "                                     initializer=Ones(), trainable=True)\n",
        "        self.beta = self.add_weight(name='beta', shape=input_shape[-1:],\n",
        "                                    initializer=Zeros(), trainable=True)\n",
        "        super(LayerNormalization, self).build(input_shape)\n",
        "    def call(self, x):\n",
        "        mean = K.mean(x, axis=-1, keepdims=True)\n",
        "        std = K.std(x, axis=-1, keepdims=True)\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "class abc(keras.layers.Layer):\n",
        "    def __init__(self,\n",
        "                 hidden_dim,\n",
        "                 **kwargs):\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.conv1=Conv1D(self.hidden_dim,1)\n",
        "        self.conv2=Conv1D(self.hidden_dim,1)\n",
        "        self.conv3=Conv1D(self.hidden_dim,1)\n",
        "        \n",
        "        self.Wq = self.Wk = self.Wv = self.Wo = None\n",
        "        self.bq = self.bk = self.bv = self.bo = None\n",
        "\n",
        "        self.intensity = self.attention = None\n",
        "        super(abc, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        \n",
        "        q, k, v = inputs\n",
        "        \n",
        "        q=self.conv1(q)\n",
        "        k=self.conv2(k)\n",
        "        v=self.conv3(v)\n",
        "        \n",
        "        \n",
        "        def scaled_dot_product_attention(inputs):\n",
        "          query, key, value = inputs\n",
        "          feature_dim = K.shape(query)[-1]\n",
        "          e = K.batch_dot(query, key, axes=2) \n",
        "          intensity = e\n",
        "          e = K.exp(e - K.max(e, axis=-1, keepdims=True))\n",
        "          attention = e / K.sum(e, axis=-1, keepdims=True)\n",
        "          v = K.batch_dot(attention, value)\n",
        "          return v\n",
        "       \n",
        "       \n",
        "        y = scaled_dot_product_attention(inputs=[q,k,v])\n",
        "        \n",
        "        \n",
        "        return y\n",
        "\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import *\n",
        "def load_model():   \n",
        "  \n",
        "  K.clear_session() \n",
        "  mod=densenet.DenseNet121(include_top=True, weights='imagenet')\n",
        "  d = mod.get_layer('conv5_block16_concat').output\n",
        "\n",
        "  inp = mod.get_layer('conv3_block12_concat').output\n",
        "  a = Reshape((28*28,512))(inp)\n",
        "  d_a = keras.layers.UpSampling2D(interpolation='bilinear',size=(4,4))(d)\n",
        "  d_a = Reshape((28*28,1024))(d_a)\n",
        "  a = abc(hidden_dim=512)([a,d_a,a])\n",
        "  a = LayerNormalization()(a)\n",
        "  a = Reshape((28,28,512,))(a)\n",
        "  a = keras.layers.GlobalAveragePooling2D()(a)\n",
        "\n",
        "  inp = mod.get_layer('conv4_block24_concat').output\n",
        "  b = Reshape((14*14,1024))(inp)\n",
        "  d_b = keras.layers.UpSampling2D(interpolation='bilinear',size=(2,2))(d)\n",
        "  d_b = Reshape((14*14,1024))(d_b)\n",
        "  b = abc(hidden_dim=1024)([b,d_b,b])\n",
        "  b = LayerNormalization()(b)\n",
        "  b = Reshape((14,14,1024,))(b)\n",
        "  b = keras.layers.GlobalAveragePooling2D()(b)\n",
        "\n",
        "  d = keras.layers.GlobalAveragePooling2D()(d)\n",
        "  \n",
        "\n",
        "  b = Dense(3, activation=\"softmax\")(b) \n",
        "  b = Reshape((-1,3))(b) \n",
        "  a = Dense(3, activation=\"softmax\")(a) \n",
        "  a = Reshape((-1,3))(a) \n",
        "  d = Dense(3, activation=\"softmax\")(d) \n",
        "  d = Reshape((-1,3))(d) \n",
        "  \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  # mod.load_weights('../input/global-3535-fold-1-1/weights.hdf5')\n",
        "  # for layer in mod.layers:\n",
        "  #   layer.trainable=False\n",
        "  a=mod.layers[-9].output\n",
        "  b=mod.layers[-10].output\n",
        "  d=mod.layers[-11].output\n",
        "  b = Dense(1, activation=\"sigmoid\")(b) \n",
        "  b = Reshape((-1,1))(b) \n",
        "  a = Dense(1, activation=\"sigmoid\")(a) \n",
        "  a = Reshape((-1,1))(a) \n",
        "  d = Dense(1, activation=\"sigmoid\")(d) \n",
        "  d = Reshape((-1,1))(d) \n",
        "  conc=Concatenate(axis=1)([a,b,d])\n",
        "  conc=keras.layers.GlobalAveragePooling1D()(conc)\n",
        "  mod=Model(inputs=mod.input,outputs=conc)\n",
        "  return mod\n",
        "\n",
        "mod=load_model()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4t7V-e99Eg-"
      },
      "source": [
        "\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "def rotate_image(image, angle):\n",
        "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
        "  return result\n",
        "def Hflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Fliplr(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def Vflip( images):\n",
        "\t\tseq = iaa.Sequential([iaa.Flipud(1.0)])\n",
        "\t\treturn seq.augment_images(images)\n",
        "def noise(images):\n",
        "    ls=[]\n",
        "    for i in images:\n",
        "        x = np.random.normal(loc=0, scale=0.05, size=(299,299,3))\n",
        "        ls.append(i+x)\n",
        "    return ls\n",
        "def rotate(images):\n",
        "    ls=[]\n",
        "    for angle in range(-15,20,5):\n",
        "        for image in images:\n",
        "            ls.append(rotate_image(image,angle))\n",
        "    return ls\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, images, labels, batch_size=64, image_dimensions = (96 ,96 ,3), shuffle=False, augment=False):\n",
        "    self.labels       = labels              # array of labels\n",
        "    self.images = images        # array of image paths\n",
        "    self.batch_size   = batch_size          # batch size\n",
        "    self.on_epoch_end()\n",
        "\n",
        "  def __len__(self):\n",
        "    return int(np.floor(self.labels.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    self.indexes = np.arange(self.labels.shape[0])\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\t\t# selects indices of data for next batch\n",
        "    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "    # select data and load images\n",
        "    labels = self.labels[indexes]\n",
        "    img = [self.images[k].astype(np.float32) for k in indexes]\n",
        "    imgH=Hflip(img)\n",
        "    imgV=Vflip(img)\n",
        "    imgR=rotate(img)\n",
        "    images=[]\n",
        "    images.extend(imgH)\n",
        "    images.extend(imgV)\n",
        "    images.extend(imgR)\n",
        "    lbl=labels.copy()\n",
        "    labels=np.repeat(labels,9)\n",
        "    del([imgV,imgR,imgH,lbl])\n",
        "    gc.collect()\n",
        "    #images = np.array([preprocess_input(img) for img in images])\n",
        "    return np.asarray(images).astype('float16'), labels.astype('uint8')\n",
        "\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UulC6f8x9GyG",
        "outputId": "f905bd0b-ff6f-4ba7-c30f-99178dd5a2ee"
      },
      "source": [
        "import cv2\n",
        "import gc\n",
        "from tensorflow.keras.optimizers import *\n",
        "train_data = DataGenerator(X_train,y_train, batch_size=4, augment=True)\n",
        "mod.compile(optimizer=Adam(1e-5,decay=1e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "hist=mod.fit_generator(train_data,epochs=50)\n",
        "gc.collect()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "81/81 [==============================] - 56s 565ms/step - loss: 0.6666 - accuracy: 0.5826\n",
            "Epoch 2/50\n",
            "81/81 [==============================] - 47s 573ms/step - loss: 0.6499 - accuracy: 0.6163\n",
            "Epoch 3/50\n",
            "81/81 [==============================] - 47s 579ms/step - loss: 0.6177 - accuracy: 0.6639\n",
            "Epoch 4/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.5679 - accuracy: 0.7085\n",
            "Epoch 5/50\n",
            "81/81 [==============================] - 48s 584ms/step - loss: 0.4732 - accuracy: 0.8193\n",
            "Epoch 6/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.3576 - accuracy: 0.8872\n",
            "Epoch 7/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.2736 - accuracy: 0.9455\n",
            "Epoch 8/50\n",
            "81/81 [==============================] - 48s 584ms/step - loss: 0.2135 - accuracy: 0.9859\n",
            "Epoch 9/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.1923 - accuracy: 0.9935\n",
            "Epoch 10/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.1863 - accuracy: 0.9949\n",
            "Epoch 11/50\n",
            "81/81 [==============================] - 48s 584ms/step - loss: 0.1828 - accuracy: 0.9955\n",
            "Epoch 12/50\n",
            "81/81 [==============================] - 47s 582ms/step - loss: 0.1796 - accuracy: 0.9962\n",
            "Epoch 13/50\n",
            "81/81 [==============================] - 47s 582ms/step - loss: 0.1772 - accuracy: 0.9966\n",
            "Epoch 14/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.1751 - accuracy: 0.9966\n",
            "Epoch 15/50\n",
            "81/81 [==============================] - 48s 584ms/step - loss: 0.1724 - accuracy: 0.9969\n",
            "Epoch 16/50\n",
            "81/81 [==============================] - 48s 584ms/step - loss: 0.1690 - accuracy: 0.9976\n",
            "Epoch 17/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.1662 - accuracy: 0.9976\n",
            "Epoch 18/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.1632 - accuracy: 0.9976\n",
            "Epoch 19/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.1599 - accuracy: 0.9976\n",
            "Epoch 20/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.2122 - accuracy: 0.9667\n",
            "Epoch 21/50\n",
            "81/81 [==============================] - 47s 582ms/step - loss: 0.2300 - accuracy: 0.9530\n",
            "Epoch 22/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.2017 - accuracy: 0.9719\n",
            "Epoch 23/50\n",
            "81/81 [==============================] - 48s 584ms/step - loss: 0.1790 - accuracy: 0.9863\n",
            "Epoch 24/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.1663 - accuracy: 0.9925\n",
            "Epoch 25/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.1601 - accuracy: 0.9942\n",
            "Epoch 26/50\n",
            "81/81 [==============================] - 47s 583ms/step - loss: 0.1542 - accuracy: 0.9966\n",
            "Epoch 27/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.1533 - accuracy: 0.9955\n",
            "Epoch 28/50\n",
            "81/81 [==============================] - 47s 582ms/step - loss: 0.1457 - accuracy: 0.9983\n",
            "Epoch 29/50\n",
            "81/81 [==============================] - 47s 582ms/step - loss: 0.1430 - accuracy: 0.9983\n",
            "Epoch 30/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.1399 - accuracy: 0.9983\n",
            "Epoch 31/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.1381 - accuracy: 0.9983\n",
            "Epoch 32/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.1330 - accuracy: 0.9993\n",
            "Epoch 33/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.1288 - accuracy: 0.9993\n",
            "Epoch 34/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.1248 - accuracy: 0.9993\n",
            "Epoch 35/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.1208 - accuracy: 0.9993\n",
            "Epoch 36/50\n",
            "81/81 [==============================] - 47s 583ms/step - loss: 0.1167 - accuracy: 0.9993\n",
            "Epoch 37/50\n",
            "81/81 [==============================] - 48s 584ms/step - loss: 0.1123 - accuracy: 0.9993\n",
            "Epoch 38/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.1078 - accuracy: 0.9993\n",
            "Epoch 39/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.1032 - accuracy: 0.9993\n",
            "Epoch 40/50\n",
            "81/81 [==============================] - 48s 584ms/step - loss: 0.0983 - accuracy: 0.9993\n",
            "Epoch 41/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.0942 - accuracy: 0.9990\n",
            "Epoch 42/50\n",
            "81/81 [==============================] - 47s 582ms/step - loss: 0.1218 - accuracy: 0.9842\n",
            "Epoch 43/50\n",
            "81/81 [==============================] - 47s 582ms/step - loss: 0.1140 - accuracy: 0.9883\n",
            "Epoch 44/50\n",
            "81/81 [==============================] - 47s 582ms/step - loss: 0.1001 - accuracy: 0.9938\n",
            "Epoch 45/50\n",
            "81/81 [==============================] - 48s 584ms/step - loss: 0.0870 - accuracy: 0.9976\n",
            "Epoch 46/50\n",
            "81/81 [==============================] - 47s 582ms/step - loss: 0.0793 - accuracy: 0.9997\n",
            "Epoch 47/50\n",
            "81/81 [==============================] - 47s 582ms/step - loss: 0.0736 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "81/81 [==============================] - 48s 583ms/step - loss: 0.0682 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "81/81 [==============================] - 48s 584ms/step - loss: 0.0633 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "81/81 [==============================] - 48s 584ms/step - loss: 0.0588 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "PD0ya6rDBGjB",
        "outputId": "4c18b5ba-9e7e-4324-afae-64bf77489cc0"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(hist.history['loss'])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcb2d2f0ed0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1MYbBZvaZBI",
        "outputId": "a3687fda-58d0-462c-a1d1-b4a446eb5981"
      },
      "source": [
        "pre=mod.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(np.round(pre),y_test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5341614906832298"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6iKXL47apzO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}